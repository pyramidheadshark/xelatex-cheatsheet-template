## Ранжирование

* **[Б]** - Базовый: Незнание этих вещей — серьезный красный флаг (уровень Hire I / No Hire).
* **[С]** - Средний: Требуется для уверенного прохождения на стажировку и уровня Hire II-III. Показывает понимание "как" и базовое "почему".
* **[П]** - Продвинутый: Вопросы на глубокое понимание "почему", математическую интуицию, связи между концепциями (уровень Hire IV).

---

## Детализированный Список Вопросов для ML Секции

**Секция 0: Общий Пайплайн и Подход**

* `[С]` Опиши полный пайплайн решения задачи бинарной классификации (от получения данных до вывода в прод). Какие этапы критически важны? (Hint: EDA, Feature Eng/Selection, Train/Val/Test Split (стратификация!), Model Selection, Baseline, Metric Choice, Training, Hyperparameter Tuning (CV), Final Evaluation, Stat Significance, Deployment Considerations).
* `[С]` Как бы ты подошел к новой ML задаче? С чего начнешь? (Hint: Понять бизнес-цель, исследовать данные (EDA), определить метрику(и), установить baseline, выбрать простую модель для старта, итеративно усложнять).
* `[С]` Что такое утечка данных (data leakage)? Приведи примеры (target leakage, train-test contamination). Как ее избежать?
* `[П]` Представь, что твоя модель показывает хорошее качество на тесте, но плохое в проде. Какие могут быть причины? (Hint: Разница в распределениях train/test/prod (covariate/concept shift), проблемы с пайплайном в проде, баги, сезонность/временной дрейф).

**Секция 1: Выбранный Алгоритм (Пример: Логистическая Регрессия)**

* **1.1 Описание Модели:**
  * `[Б]` Что такое Логистическая Регрессия? Для каких задач? (Hint: Бинарная классификация, предсказание вероятности).
  * `[Б]` **ЗАПИШИ** формулу модели LogReg. Что она предсказывает? (Hint: $P(y=1|x) = \sigma(w^T x)$).
  * `[Б]` Что такое сигмоида $\sigma(z)$? **ЗАПИШИ** ее формулу. Нарисуй график. Каков диапазон ее значений? (Hint: $\frac{1}{1+e^{-z}}$, (0,1)).
  * `[С]` Что такое $w^T x$? Как называется эта часть? (Hint: Логит, линейная комбинация).
  * `[С]` Почему нельзя использовать обычную линейную регрессию для бинарной классификации? (Hint: Выход за пределы, неверные статистические предположения).
  * `[П]` Можно ли заменить сигмоиду на другую функцию? (например, probit, tanh rescaled). Что от такой функции требуется? (Hint: Монотонность, гладкость, отображение в или около того). На что повлияет замена? (Hint: Интерпретация коэффициентов, форма функции потерь).
  * `[П]` Как связаны параметры $w$ с Odds Ratio (отношением шансов)? (Hint: $OR = e^{w_j}$ для изменения $x_j$ на 1).
* **1.2 Функция Потерь (Loss Function):**
  * `[Б]` Какая функция потерь используется в LogReg? **ЗАПИШИ** ее формулу (LogLoss / Бинарная Кросс-Энтропия). (Hint: $- [ y \log(\hat{p}) + (1-y) \log(1-\hat{p}) ]$ для одного объекта).
  * `[С]` **ЗАПИШИ** формулу LogLoss для всей выборки.
  * `[С]` Объясни интуитивно, почему LogLoss работает (как штрафует ошибки)? (Hint: Сильный штраф за уверенные ошибки, малый - за уверенные правильные ответы).
  * `[С]` Почему нельзя использовать MSE для LogReg? (Hint: Невыпуклость Loss -> локальные минимумы для GD).
  * `[П]` Откуда берется формула LogLoss? (Hint: Принцип Максимального Правдоподобия (MMP) для распределения Бернулли. Уметь идейно вывести, как в логах).
  * `[П]` Зачем при выводе из ММП логарифмируют правдоподобие? (Hint: Произведение -> сумма (проще производная), численная стабильность, возможность SGD).
* **1.3 Обучение Модели (Оптимизация):**
  * `[Б]` Как называется основной метод обучения LogReg? (Hint: Градиентный спуск).
  * `[Б]` **ЗАПИШИ** формулу шага обновления веса $w_k$ в GD. (Hint: $w_k := w_k - \alpha \frac{\partial J}{\partial w_k}$).
  * `[С]` **ЗАПИШИ** формулу для $\frac{\partial J}{\partial w_k}$ (градиент LogLoss). Объясни ее компоненты. (Hint: $\frac{1}{m} \sum (\hat{p}^{(i)} - y^{(i)}) x_k^{(i)}$).
  * `[С]` На что влияет скорость обучения $\alpha$? Что будет при неверном выборе?
  * `[С]` Сравни Batch GD, Mini-batch GD, SGD. Плюсы/минусы. Какой чаще используется? (Hint: Trade-off: скорость итерации vs точность градиента vs стабильность).
  * `[П]` Сходится ли GD для LogReg? Гарантированно ли? К чему? Почему? (Hint: Да, к глоб. минимуму, т.к. LogLoss выпуклая). (Доказательство выпуклости - hard).
  * `[П]` Как инициализация весов влияет на результат LogReg? (Hint: На конечный результат не влияет (из-за выпуклости), но влияет на кол-во итераций).
  * `[П]` Какие еще методы оптимизации ты знаешь, кроме GD-вариантов? (Hint: LBFGS (квази-ньютоновский, часто в sklearn по умолч.), Newton). Опиши идею метода Ньютона. (Hint: Использует Гессиан (матрицу вторых производных), быстрее сходится вблизи минимума).
  * `[П]` Почему метод Ньютона редко используют для больших моделей? (Hint: Вычисление и обращение Гессиана $\mathbf{H}$ затратно: $O(n^3)$ или $O(n^2)$ памяти).
  * `[П]` Что такое ADAM? Опиши основные идеи. Почему он часто работает хорошо? (Hint: Адаптивные learning rates для каждого параметра + Momentum (инерция). Комбинирует идеи AdaGrad/RMSProp и Momentum).
* **1.4 Практические Аспекты:**
  * `[С]` Нужно ли масштабировать признаки для LogReg? Зачем? (Hint: Да, для ускорения сходимости GD и корректной работы регуляризации).
  * `[П]` Существует ли аналитическое решение для LogReg? (Hint: Нет, в отличие от ЛинРег с MSE).

**Секция 2: Деревья и Ансамбли**

* **2.1 Дерево Решений:**
  * `[Б]` Как строится дерево решений (общая идея)? (Hint: Жадный рекурсивный поиск лучшего сплита).
  * `[С]` **ЗАПИШИ** формулы для Gini Impurity и Entropy. Объясни их смысл. Что такое Information Gain?
  * `[С]` К какому типу ошибки (Bias/Variance) склонно одно глубокое дерево? Как с этим бороться? (Hint: High Variance; ограничение глубины/листьев, pruning).
  * `[П]` Сравни Gini и Entropy. Есть ли большая разница на практике? (Hint: Очень похожи, Entropy чуть медленнее из-за логарифма. Gini стремится изолировать самый частый класс, Entropy - к более сбалансированным сплитам).
  * `[П]` Как дерево работает с категориальными признаками? С пропусками?
* **2.2 Random Forest:**
  * `[Б]` Что такое RF? На каких двух основных идеях основан? (Hint: Bagging + Random Subspace).
  * `[С]` Объясни Bagging и Random Subspace. Зачем нужен второй компонент? (Hint: Декорреляция деревьев).
  * `[С]` Как RF влияет на Bias/Variance? (Hint: $\downarrow$ Variance, $\approx$ Bias).
  * `[С]` Как оценить важность признаков в RF? (MDI vs Permutation Importance). Какой метод и почему предпочтительнее для оценки реальной предсказательной силы? (Hint: Permutation на val/OOB).
  * `[С]` Какие основные гиперпараметры у RF? (`n_estimators`, `max_features`, `max_depth` и т.д.). Как они влияют на модель?
  * `[П]` Можно ли переобучить RF числом деревьев? (Hint: Обычно нет, ошибка выходит на плато). За счет чего тогда RF может переобучиться? (Hint: За счет параметров отдельных деревьев - глубины и т.п.).
* **2.3 Gradient Boosting (GBM):**
  * `[Б]` В чем основная идея GBM? Чем отличается от RF? (Hint: Последовательность, исправление ошибок).
  * `[С]` На чем обучается $m$-ое дерево? (Hint: Градиент Loss от предсказаний $F_{m-1}$).
  * `[С]` Зачем нужен Learning Rate? Что будет при $\nu=1$?
  * `[С]` Как GBM решает задачу классификации? Что предсказывает дерево? Можно ли использовать MSE? (Hint: Предсказывает изменение логита/вероятности. MSE - нет).
  * `[П]` **ЗАПИШИ** формулу псевдо-остатков для бинарной классификации с LogLoss.
  * `[П]` Сравни XGBoost, LightGBM, CatBoost (основные фишки). (Hint: XGB: Регуляризация L1/L2 на листья, 2-я производная. LGBM: Leaf-wise, GOSS, EFB, категор. фичи. CatBoost: Ordered TS, Oblivious Trees, категор. фичи).
  * `[П]` Можно ли переобучить GBM числом деревьев? (Hint: Да). Как это отследить и предотвратить? (Hint: Early stopping по валидационной метрике).
  * `[П]` Как GBM работает с категориальными признаками? (Hint: Зависит от реализации - OHE, Target Encoding (риск утечки), спец. методы в LGBM/CatBoost).

**Секция 3: Нейронные Сети (Базовый Уровень для Стажера)**

* `[Б]` Что такое MLP (Многослойный Перцептрон)? Чем отличается от LogReg? (Hint: Наличие скрытых слоев с нелинейностями).
* `[С]` Зачем нужны функции активации (нелинейности)? Что если их убрать? (Hint: Без них - линейная модель). Назови 2-3 популярных (ReLU, Sigmoid).
* `[С]` Как обучается нейросеть? (Общая идея GD + Backpropagation).
* `[С]` Что такое эпоха, батч в контексте обучения NN?
* `[С]` Что такое Batch Normalization? Зачем? (Hint: Стабилизация/ускорение обучения).
* `[С]` Что такое Dropout? Зачем? (Hint: Регуляризация).
* `[П]` Сколько обучаемых параметров в полносвязном слое с $N_{in}$ входами и $N_{out}$ выходами (с учетом bias)? (Hint: $N_{in} \times N_{out} + N_{out}$).
* `[П]` Опиши проблему затухающих/взрывающихся градиентов. Как с ней борются? (Hint: ReLU, BN, ResNet, grad clipping, init).

**Секция 4: Метрики Качества**

* `[Б]` **ЗАПИШИ** формулы P, R, F1. Объясни их смысл.
* `[Б]` Чем плоха Accuracy при дисбалансе?
* `[С]` В каких ситуациях важнее Precision, а в каких Recall? Приведи примеры.
* `[С]` Почему F1 - гармоническое среднее? Что будет, если взять арифметическое?
* `[С]` Что такое ROC AUC? Оси ROC кривой? Интерпретация AUC?
* `[С]` Что такое PR AUC? Оси PR кривой?
* `[П]` Почему PR AUC предпочтительнее ROC AUC при сильном дисбалансе и фокусе на минорном классе? Объясни через FP/TN.
* `[П]` Как выглядит PR кривая для случайного классификатора? Как она зависит от баланса классов? (Hint: Горизонтальная линия $y = \text{доля позитивного класса}$).
* `[П]` Что такое $F_\beta$-мера? Когда ее используют? (Hint: Взвешенный вариант F1, $\beta > 1$ - важнее Recall, $\beta < 1$ - важнее Precision).

**Секция 5: Переобучение и Регуляризация**

* `[Б]` Что такое переобучение? Как его обнаружить? (Hint: Графики train/validation loss/metric).
* `[Б]` Назови 3-4 способа борьбы с переобучением. (Hint: Регуляризация, упрощение модели, больше данных, Dropout, ансамбли).
* `[С]` Что такое регуляризация? Зачем нужна?
* `[С]` **ЗАПИШИ** формулы L1 и L2 регуляризации (штрафы). В чем их главное отличие в эффекте на веса? (Hint: L1 - обнуляет (sparsity), L2 - сжимает (shrinkage)).
* `[С]` Нужно ли масштабировать данные перед применением регуляризации? Почему?
* `[П]` Почему L1 приводит к разреженности (обнулению весов)? (Геометрическая/алгебраическая интуиция).
* `[П]` Как регуляризация влияет на Bias-Variance разложение? (Hint: $\uparrow \lambda \implies \uparrow Bias, \downarrow Variance$).
* `[П]` Как выбрать коэффициент регуляризации $\lambda$? (Hint: Кросс-валидация).
* `[П]` Что такое Elastic Net? Когда он может быть полезен? (Hint: Комбинация L1/L2. Полезна при сильной корреляции признаков и когда нужно и отбирать, и стабилизировать).

**Секция 6: Валидация и Оценка Модели**

* `[Б]` Зачем делить данные на train/validation/test? Роль каждой части?
* `[С]` Что такое K-Fold CV? Stratified K-Fold? Зачем стратификация?
* `[П]` Как правильно проводить подбор гиперпараметров и оценку финальной модели с использованием CV? (Hint: Nested CV или Train/Val/Test с CV на Train+Val).
* `[П]` Как валидировать модели на временных рядах? Какие есть подводные камни? (Hint: TimeSeriesSplit, Forward Chaining, нельзя перемешивать, утечки из будущего).
* `[П]` Опиши схему применения ресемплинга (SMOTE/Under-sampling) в связке с CV. (Hint: Resample **только** на обучающем фолде *внутри* каждого шага CV).

**Секция 7: Статистическая Значимость**

* `[Б]` Метрика на тесте - это точное значение качества модели? Почему? (Hint: Нет, случайная величина, зависит от конкретного теста).
* `[С]` Сравниваем модели A и B на тесте. A дала AUC 0.85, B - 0.83. Можно ли точно сказать, что A лучше? Что нужно сделать? (Hint: Нет. Нужна проверка стат. значимости разницы).
* `[С]` Как можно сравнить модели A и B, оцененные на K фолдах CV? Какой тест использовать? (Hint: Парный t-тест / Уилкоксона на K парах метрик).
* `[П]` Как оценить стат. значимость разницы на *одном* тесте? Опиши метод Bootstrap. (Hint: Много раз сэмплируем тест с возвращением -> считаем разницу метрик -> строим ДИ для разницы -> проверяем, включает ли 0).
* `[П]` Что такое p-value? Как его интерпретировать? Что такое уровень значимости $\alpha$? Ошибки I и II рода?
