## Углубленный Конспект: Деревья Решений и Ансамблевые Методы

### Часть 0: Введение

* **Дерево Решений (Decision Tree):** Непараметрический алгоритм supervised learning, используемый для задач классификации и регрессии. Модель представляет собой структуру, похожую на блок-схему или перевернутое дерево, где внутренние узлы представляют проверки признаков, ветви - результаты проверок, а листья - итоговые предсказания (класс или числовое значение).
* **Ансамблевые Методы (Ensemble Methods):** Класс алгоритмов, которые объединяют предсказания нескольких базовых моделей (часто деревьев решений) для получения более качественного и стабильного итогового предсказания, чем могла бы дать одна базовая модель. Основные идеи: "мудрость толпы", снижение общей ошибки за счет компенсации ошибок отдельных моделей.

### Часть 1: Дерево Решений (Decision Tree)

#### 1.1. Структура и Предсказание

* **Компоненты:**
  * **Корневой узел (Root Node):** Самый верхний узел, представляет всю выборку.
  * **Внутренний узел (Internal Node):** Узел, который проверяет значение одного из признаков ($x_j$) по некоторому условию (например, $x_j \le \text{порог}$ для числовых, $x_j = \text{значение}$ для категориальных). Имеет дочерние узлы.
  * **Ветвь (Branch):** Соединяет узлы, представляет результат проверки в родительском узле.
  * **Лист (Leaf Node / Terminal Node):** Конечный узел, не имеющий дочерних узлов. Содержит итоговое предсказание.
* **Процесс Предсказания:** Для нового объекта $x$ мы начинаем с корневого узла и движемся вниз по дереву, выполняя проверки в узлах и переходя по соответствующим ветвям, пока не достигнем листа. Значение в этом листе и будет предсказанием $\hat{y}$ для объекта $x$.
* **Предсказание в Листе:**
  * **Классификация:** Чаще всего – **метка самого частого класса** (majority class) среди обучающих объектов, попавших в этот лист. Можно также предсказывать вероятности классов (доля объектов каждого класса в листе).
  * **Регрессия:** Чаще всего – **среднее значение** целевой переменной $y$ по всем обучающим объектам, попавшим в этот лист.

#### 1.2. Построение Дерева (Алгоритм CART-типа)

* **Идея:** Рекурсивное разбиение (Recursive Partitioning). Начиная с корневого узла (содержащего все данные), мы ищем наилучшее возможное разделение (сплит) данных на две (или более) подгруппы на основе одного из признаков. Этот процесс повторяется для каждой полученной подгруппы (становящейся новым узлом), пока не будет выполнен критерий остановки.
* **Ключевая Задача: Найти "Лучший" Сплит:** В каждом узле алгоритм должен решить:
    1. Какой признак $j$ использовать для разделения?
    2. Какое условие (порог для числовых, значение для категориальных) применить к этому признаку?
    "Лучший" сплит – это тот, который делает дочерние узлы максимально "чистыми" (однородными) по целевой переменной $y$.
* **Алгоритм Поиска Лучшего Сплита (Жадный Подход):**
    1. Для **каждого** признака $j$ (от 1 до $n$):
        * Определить множество возможных условий/порогов для этого признака. (Для числовых - обычно пороги между уникальными отсортированными значениями; для категориальных - подмножества значений).
        * Для **каждого** возможного условия/порога:
            * Разделить данные в текущем узле на дочерние узлы (например, левый и правый).
            * Рассчитать **критерий качества** этого разделения (насколько "чище" стали дочерние узлы по сравнению с родительским). Основной критерий - **Information Gain (IG)** или его аналоги.
    2. Выбрать тот признак $j^*$ и то условие/порог $t^*$, которые дали **максимальное** значение критерия качества (например, максимальный IG).
    3. Этот лучший сплит используется для создания дочерних узлов.
* **Критерии "Чистоты" Узла (Impurity Measures):** Измеряют неоднородность классов (для классификации) или разброс значений (для регрессии) в узле. Цель сплита - уменьшить эту нечистоту.
  * **Gini Impurity (Индекс Джини) - для Классификации:**
    * **Определение:** Мера того, насколько вероятно, что случайно выбранный элемент из узла будет неправильно классифицирован, если ему присвоить случайный класс в соответствии с распределением классов в этом узле.
    * **Формула:** $G = \sum_{k=1}^{K} p_k (1 - p_k) = 1 - \sum_{k=1}^{K} p_k^2$
      * $K$ - количество классов.
      * $p_k$ - доля объектов класса $k$ в данном узле.
    * **Свойства:** $G=0$ для "чистого" узла (все объекты одного класса). Максимум достигается при равномерном распределении классов.
  * **Entropy (Энтропия) - для Классификации:**
    * **Определение:** Мера неопределенности или хаоса в распределении классов в узле (из теории информации).
    * **Формула:** $H = - \sum_{k=1}^{K} p_k \log_2(p_k)$
      * (При $p_k=0$, считаем $p_k \log_2(p_k) = 0$).
    * **Свойства:** $H=0$ для "чистого" узла. Максимум при равномерном распределении.
  * **Variance (Дисперсия) - для Регрессии:**
    * **Определение:** Мера разброса истинных значений $y$ относительно их среднего в узле.
    * **Формула:** $Var = \frac{1}{N_{node}} \sum_{i \in \text{node}} (y^{(i)} - \bar{y}_{node})^2$
      * $N_{node}$ - число объектов в узле.
      * $\bar{y}_{node}$ - среднее значение $y$ в узле.
    * (Часто эквивалентно минимизации MSE внутри узла).
* **Критерий Качества Сплита: Information Gain (IG) / Прирост Информации:**
  * **Определение:** Насколько уменьшилась нечистота (или дисперсия) после выполнения сплита по сравнению с родительским узлом.
  * **Формула (Общая):**
        $IG(\text{Parent, Split}) = \text{Impurity}(\text{Parent}) - \sum_{\text{Child } c} \frac{N_c}{N_{\text{Parent}}} \text{Impurity}(\text{Child } c)$
    * $\text{Impurity}$ - мера нечистоты (Gini, Entropy или Variance).
    * $N_c$ - число объектов в дочернем узле $c$.
    * $N_{\text{Parent}}$ - число объектов в родительском узле.
    * Суммирование идет по всем дочерним узлам, полученным в результате сплита.
  * **Использование:** Алгоритм выбирает сплит, который **максимизирует** Information Gain.

#### 1.3. Остановка Роста и Борьба с Переобучением

* **Проблема Переобучения:** Если не ограничивать рост дерева, оно будет продолжать делиться, пока каждый лист не станет "чистым" или не будет содержать только один объект. Такое дерево идеально запомнит обучающую выборку (низкий Bias), но будет очень чувствительно к шуму и особенностям данных, плохо обобщаясь на новые данные (**высокий Variance**).
* **Методы Борьбы:**
    1. **Pre-pruning (Предварительная обрезка / Критерии Остановки):** Не давать дереву расти слишком сильно. Остановить разделение узла, если:
        * Достигнута максимальная глубина (`max_depth`).
        * Узел содержит слишком мало объектов (`min_samples_split`).
        * Потенциальный дочерний узел будет содержать слишком мало объектов (`min_samples_leaf`).
        * Достигнуто максимальное число листьев (`max_leaf_nodes`).
        * Прирост информации (IG) от лучшего сплита меньше некоторого порога.
    2. **Post-pruning (Обрезка после построения):** Построить полное (или глубокое) дерево, а затем "обрезать" ветви, которые не дают значимого улучшения качества.
        * **Cost Complexity Pruning (CCP) / Обрезка по стоимости сложности (Метод минимальной стоимости-сложности):**
            * **Идея:** Найти баланс между точностью дерева и его сложностью (числом листьев).
            * **Функционал:** $R_\alpha(T) = R(T) + \alpha |T|$
                * $T$ - дерево (или поддерево).
                * $R(T)$ - суммарная ошибка (или нечистота) листьев дерева $T$.
                * $|T|$ - количество листьев в дереве $T$.
                * $\alpha \ge 0$ - **параметр сложности (complexity parameter)**. Контролирует штраф за сложность. Чем больше $\alpha$, тем сильнее обрезка.
            * **Алгоритм:** Для разных значений $\alpha$ находятся оптимальные поддеревья, минимизирующие $R_\alpha(T)$. Оптимальное $\alpha$ (в sklearn `ccp_alpha`) подбирается по кросс-валидации.

#### 1.4. Плюсы и Минусы Деревьев Решений

* **Плюсы:**
  * **Интерпретируемость:** Легко понять и визуализировать логику принятия решений.
  * **Не требуют масштабирования признаков:** Разбиения не зависят от масштаба.
  * **Работают с категориальными и числовыми признаками.**
  * **Неявно выполняют отбор признаков** (используются только информативные).
* **Минусы:**
  * **Склонность к переобучению (высокий Variance).**
  * **Нестабильность:** Небольшие изменения в данных могут привести к построению совершенно другого дерева.
  * **Жадный алгоритм построения:** Не гарантирует нахождения глобально оптимального дерева.
  * **Сложно улавливают линейные зависимости.**
  * Могут создавать смещенные деревья, если классы несбалансированы.

### Часть 2: Ансамблевые Методы - Общие Принципы

* **Мотивация:** Объединение нескольких моделей часто дает лучший результат, чем одна, даже самая лучшая модель.
* **Снижение Ошибки:**
  * **Bagging:** Уменьшает ошибку за счет **снижения Variance** (усреднение независимых или слабо коррелирующих ошибок).
  * **Boosting:** Уменьшает ошибку за счет **снижения Bias** (последовательное исправление ошибок), а также может снижать Variance (через learning rate, ограничения на деревья).
* **Основные Типы:**
  * **Bagging (Bootstrap Aggregating):** Обучение одинаковых моделей на разных подвыборках данных (бутстрэпах), предсказания усредняются/голосуются. Пример: Random Forest.
  * **Boosting:** Последовательное построение моделей, где каждая следующая фокусируется на ошибках предыдущих. Пример: AdaBoost, Gradient Boosting (GBM, XGBoost, LightGBM, CatBoost).
  * **Stacking (Стекинг):** Обучение нескольких разных моделей (уровень 0), их предсказания используются как признаки для мета-модели (уровень 1), которая делает финальное предсказание.

### Часть 3: Bagging и Random Forest (RF)

#### 3.1. Bagging

* **Определение:** Метод ансамблирования, использующий **Bootstrap** для создания множества обучающих подвыборок и **Aggregating** для объединения предсказаний базовых моделей, обученных на этих подвыборках.
* **Bootstrap Сэмплирование:** Для создания $B$ подвыборок (где $B$ - число базовых моделей): из исходной обучающей выборки размера $m$ случайным образом выбирается $m$ объектов **с возвращением**. В среднем, каждая bootstrap-выборка содержит около 63.2% уникальных объектов из исходной, остальные $\approx$ 36.8% остаются "за бортом" (Out-of-Bag).
* **Обучение и Агрегация:** На каждой из $B$ bootstrap-выборок обучается **независимая** базовая модель (например, дерево решений). Итоговое предсказание ансамбля:
  * **Регрессия:** Среднее арифметическое предсказаний всех $B$ моделей.
  * **Классификация:** Голосование большинством (majority voting) классов, предсказанных $B$ моделями (или усреднение вероятностей, если модели их выдают).
* **Эффект на Bias-Variance:** Bagging эффективен для моделей с **высоким Variance** и низким Bias (как глубокие деревья). Усреднение предсказаний множества таких моделей, обученных на разных данных, **значительно снижает Variance** итогового ансамбля, при этом **Bias почти не меняется** (или незначительно увеличивается).

#### 3.2. Random Forest (RF)

* **Определение:** Ансамблевый метод, который применяет **Bagging** к **деревьям решений**, но с дополнительной модификацией: при построении каждого дерева, в каждом узле для поиска лучшего сплита используется не все признаки, а только **случайное подмножество признаков** (Random Subspace).
* **Random Subspace (Выбор Подмножества Признаков):**
  * Перед поиском лучшего сплита в очередном узле, алгоритм случайным образом выбирает $k$ признаков из общего числа $n$ доступных признаков (где $k$ - гиперпараметр `max_features`, обычно $k \approx \sqrt{n}$ для классификации и $k \approx n/3$ для регрессии).
  * Поиск лучшего сплита ведется **только среди этих $k$ признаков**.
  * На следующем узле выбирается новое случайное подмножество $k$ признаков.
  * **Цель:** Уменьшить корреляцию между деревьями в ансамбле. Если есть очень сильный признак, без этого шага он выбирался бы для сплита во многих деревьях, делая их похожими. Random Subspace заставляет деревья использовать и менее сильные признаки, делая их более разнообразными. Это **еще сильнее снижает Variance** ансамбля.
* **Алгоритм Построения RF:**
    1. Для $b = 1$ до $B$ (число деревьев):
        a.  Создать bootstrap-выборку $D_b$ из исходных данных $D$.
        b.  Построить дерево решений $T_b$ на выборке $D_b$:
            *Начинаем с корневого узла.
            *   Рекурсивно для каждого узла:
                i.  Выбрать случайное подмножество $k$ признаков (`max_features`).
                ii. Найти лучший сплит (признак + порог/значение) **только среди этих $k$ признаков**, используя критерий Gini/Entropy/Variance Reduction.
                iii. Разделить узел на дочерние.
                iv. Повторять, пока не выполнен критерий остановки (для RF часто используются довольно глубокие деревья, но с ограничениями вроде `min_samples_leaf`).
    2. Итоговый ансамбль: $\{T_1, T_2, ..., T_B\}$.
* **Предсказание RF:** Агрегация предсказаний всех деревьев $T_b$ (усреднение для регрессии, голосование/усреднение вероятностей для классификации).
* **Out-of-Bag (OOB) Оценка:**
  * **OOB-образцы для дерева $T_b$:** Объекты из исходной выборки $D$, которые не попали в bootstrap-выборку $D_b$.
  * **OOB-предсказание для объекта $x_i$:** Усреднить/проголосовать предсказания только тех деревьев $\{T_b\}$, для которых $x_i$ был OOB-образцом.
  * **OOB-ошибка:** Посчитать метрику качества (Accuracy, F1, MSE, ...) сравнивая OOB-предсказания со истинными $y_i$ для всех (или почти всех) объектов $i$. Дает оценку производительности модели без необходимости отдельной валидационной выборки (но CV все же надежнее).
* **Оценка Важности Признаков (Feature Importance):**
    1. **Mean Decrease in Impurity (MDI) / Gini Importance:**
        * **Как считается:** Для каждого признака $j$ суммируется уменьшение нечистоты (Gini/Entropy/Variance), которое он внес при каждом сплите по нему во всех деревьях ансамбля, взвешенное на долю объектов, прошедших через этот сплит. Результат усредняется по всем деревьям.
        * **Плюсы:** Быстро считается (побочный продукт обучения).
        * **Минусы:** Считается **на обучающих данных**, склонна **завышать важность** числовых признаков с большим количеством уникальных значений и категориальных признаков с высокой кардинальностью. Может некорректно распределять важность между **сильно коррелирующими** признаками. **Менее надежна.**
    2. **Permutation Importance / Mean Decrease in Accuracy (MDA):**
        * **Как считается:**
            a.  Обучить RF и посчитать базовую метрику качества $S_{base}$ на OOB-выборке (или отдельной валидационной/тестовой).
            b.  Для каждого признака $j$:
                i.  **Перемешать** значения признака $j$ в OOB-выборке (разрушить связь между признаком $j$ и $y$).
                ii. Сделать предсказания с помощью **уже обученного** RF на данных с перемешанным признаком $j$.
                iii. Посчитать метрику качества $S_j$ на этих предсказаниях.
                iv. Важность признака $j = S_{base} - S_j$ (или $S_{base} / S_j$).
            c.  Повторить шаги (b.i - b.iv) несколько раз и усреднить важности для стабильности.
        * **Плюсы:** Оценивает **реальную предсказательную силу** признака на "новых" данных. **Более надежна**, менее смещена. Работает для любой модели.
        * **Минусы:** Вычислительно дороже, чем MDI.
* **Основные Гиперпараметры:**
  * `n_estimators`: Число деревьев. Больше -> лучше (до плато), но дольше обучение.
  * `max_features`: Число признаков для выбора сплита. Ключевой для декорреляции и Bias-Variance tradeoff.
  * Параметры деревьев: `max_depth`, `min_samples_split`, `min_samples_leaf` (контролируют сложность отдельных деревьев и переобучение ансамбля).
  * `bootstrap=True`: Использовать ли бутстрэп.
  * `oob_score=True`: Считать ли OOB-ошибку.
* **Переобучение RF:** Обычно RF устойчив к переобучению при увеличении `n_estimators` (ошибка выходит на плато). Переобучение возможно, если **отдельные деревья слишком сложные** (не ограничены по глубине/листьям).

### Часть 4: Gradient Boosting Machines (GBM)

#### 4.1. Основная Идея

* **Определение:** Последовательный ансамблевый метод, где базовые модели (обычно деревья) строятся одна за другой, и каждая новая модель пытается **исправить ошибки (остатки или псевдо-остатки)**, допущенные предыдущим ансамблем.
* **Отличие от Bagging/RF:** Модели строятся **зависимо**, не параллельно. Цель - не усреднение, а **постепенное улучшение** предсказаний.
* **Эффект на Bias-Variance:** GBM обычно **сильно снижает Bias** за счет фокусировки на ошибках. Variance также контролируется за счет использования **слабых базовых моделей** (неглубоких деревьев) и **механизмов регуляризации** (learning rate, ограничения деревьев, регуляризация в XGBoost).

#### 4.2. Алгоритм GBM

* **Идея:** Рассматривать обучение как оптимизацию (минимизацию) некоторой **дифференцируемой функции потерь $L(y, F(x))$** в пространстве функций, где $F(x)$ - текущее предсказание ансамбля. Мы делаем шаги в этом пространстве, добавляя новые функции (деревья) $h_m(x)$, которые направлены в сторону **анти-градиента функции потерь**.
* **Шаги Алгоритма (для Базовых Моделей - Деревьев):**
    1. **Инициализация:** Задать начальное предсказание ансамбля $F_0(x)$. Обычно это константа, минимизирующая функцию потерь (например, среднее $\bar{y}$ для MSE, логарифм отношения шансов для LogLoss).
    2. **Цикл по итерациям (деревьям) $m = 1$ до $M$:**
        a.  **Вычисление Псевдо-Остатков:** Для каждого объекта $i$ (от 1 до $m$) вычислить **отрицательный градиент функции потерь $L$ по предсказанию $F$ предыдущего ансамбля $F_{m-1}$**:
            $r_{im} = - \left[ \frac{\partial L(y_i, F(x_i))}{\partial F(x_i)} \right]_{F(x_i) = F_{m-1}(x_i)}$
            *(Эти $r_{im}$ показывают, в какую сторону и насколько сильно нужно изменить предсказание $F_{m-1}(x_i)$, чтобы уменьшить ошибку $L$ для $i$-го объекта).*
        b.  **Обучение Базовой Модели:** Обучить "слабую" модель (например, дерево решений небольшой глубины) $h_m(x)$ на обучающей выборке $(x_i, r_{im})$, т.е. заставить ее предсказывать псевдо-остатки.
        c.  **Обновление Ансамбля:** Добавить предсказание новой модели $h_m(x)$ к предсказанию ансамбля, используя **скорость обучения (learning rate) $\nu$** (малое число, < 1, обычно 0.01-0.1):
            $F_m(x) = F_{m-1}(x) + \nu \cdot h_m(x)$
            *(Параметр $\nu$ (eta) уменьшает вклад каждого дерева, делая обучение более робастным и предотвращая переобучение. Иногда шаг $\nu$ подбирается или используется оптимальный шаг для листьев дерева).*
* **Функции Потерь (Примеры):**
  * Регрессия: MSE $L = \frac{1}{2}(y-F)^2 \implies r = -(F-y) = y-F$ (обычные остатки). MAE $L = |y-F| \implies r = \text{sign}(y-F)$.
  * Бинарная Классификация: LogLoss $L = -[y \log(p) + (1-y)\log(1-p)]$, где $p=\sigma(F)$. Градиент сложнее, но $r = y - p$ (разница между истиной и предсказанной вероятностью). $F(x)$ здесь - это **логит** (выход до сигмоиды). Дерево $h_m(x)$ предсказывает изменение логита.

#### 4.3. Ключевые Аспекты и Регуляризация

* **Learning Rate ($\nu$ / eta):** Важнейший гиперпараметр. Меньше $\nu$ -> нужно больше деревьев $M$, обучение медленнее, но модель более робастная. Больше $\nu$ -> быстрее сходится, но выше риск переобучения.
* **Число Деревьев ($M$ / n_estimators):** Слишком мало -> недообучение. Слишком много -> **переобучение** (в отличие от RF). Оптимальное число деревьев подбирается по **кросс-валидации** с использованием **Early Stopping** (остановить обучение, когда метрика на валидационном сете перестает улучшаться или начинает ухудшаться).
* **Сложность Деревьев:** Базовые деревья в GBM обычно делают **неглубокими** (`max_depth` 3-8), чтобы они были "слабыми" и чтобы контролировать Variance. Используются те же параметры (`min_samples_leaf`, etc.), что и для обычных деревьев.
* **Subsampling (Стохастический градиентный бустинг):** На каждой итерации $m$ дерево $h_m(x)$ обучается не на всей выборке, а на ее случайной **подвыборке** (без возвращения, обычно 50-80%). Это вносит случайность, ускоряет обучение и помогает бороться с переобучением (по аналогии с Mini-batch GD).
* **Регуляризация в Реализациях (XGBoost):** XGBoost добавляет L1 и L2 регуляризацию на **веса (значения) в листьях** деревьев, что дополнительно контролирует сложность модели.

#### 4.4. Популярные Библиотеки Бустинга

* **XGBoost:**
  * Регуляризация L1/L2 на веса листьев.
  * Использование **вторых производных** (Гессиана) для более точного построения деревьев.
  * Эффективная обработка пропусков.
  * Параллельные вычисления.
* **LightGBM:**
  * **Leaf-wise** рост дерева (вместо level-wise), что быстрее, но может требовать ограничения `max_depth`.
  * **GOSS** (Gradient-based One-Side Sampling): Уделяет больше внимания объектам с большими градиентами (ошибками).
  * **EFB** (Exclusive Feature Bundling): Объединяет взаимоисключающие разреженные признаки для ускорения.
  * Очень быстрый и эффективный по памяти.
  * Встроенная обработка категориальных признаков.
* **CatBoost:**
  * **Ordered Target Statistics (TS):** Продвинутый метод кодирования категориальных признаков, борется с утечкой таргета.
  * **Oblivious Trees (Симметричные деревья):** Используют один и тот же признак/порог на всем уровне дерева. Ускоряет предсказание, действует как неявная регуляризация.
  * Хорошо работает "из коробки", часто не требует тщательного подбора гиперпараметров.
  * Встроенная обработка категорий и их комбинаций.
