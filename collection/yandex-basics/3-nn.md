## Углубленный Конспект: Нейронные Сети

### Часть 1: Базовые Компоненты

#### 1.1 Нейрон / Перцептрон

1. **Определение:** **Нейрон** (или узел) – это фундаментальная вычислительная единица нейронной сети. Он получает один или несколько входов, выполняет над ними простое вычисление и передает результат дальше.
2. **Модель Искусственного Нейрона:**
    * **Шаг 1: Взвешенная Сумма (Линейная часть):** Нейрон вычисляет взвешенную сумму своих входов ($x_1, ..., x_n$) с соответствующими весами ($w_1, ..., w_n$) и добавляет смещение ($b$). Это значение часто называют **логит** или **преактивация** ($z$).
        * **Скалярная форма:** $z = (w_1 x_1 + w_2 x_2 + \dots + w_n x_n) + b = \sum_{j=1}^{n} w_j x_j + b$
        * **Векторная форма:** $z = w^T x + b$
            * $x$: вектор входов размерности $n \times 1$.
            * $w$: вектор весов размерности $n \times 1$.
            * $b$: смещение (bias), скаляр.
            * $w^T$: транспонированный вектор весов (строка).
    * **Шаг 2: Функция Активации:** Результат $z$ пропускается через **функцию активации** $f(\cdot)$, чтобы получить выходное значение нейрона, называемое **активацией** ($a$).
        * **Скалярная форма:** $a = f(z) = f(\sum_{j=1}^{n} w_j x_j + b)$
3. **Обучаемые Параметры:** Веса $w_1, ..., w_n$ и смещение $b$ являются **обучаемыми параметрами** нейрона. Их значения подбираются в процессе обучения сети для минимизации ошибки.
4. **Перцептрон:** Исторически, **перцептрон Розенблатта** – это модель одного нейрона с пороговой функцией активации (например, ступенькой), использовавшаяся для бинарной классификации. В современном контексте, термин "перцептрон" иногда используют для обозначения одного нейрона или слоя нейронов. **Многослойный перцептрон (MLP)** – это нейронная сеть, состоящая из нескольких полносвязных слоев нейронов.

#### 1.2 Функции Активации

1. **Определение:** **Функция активации** $f(z)$ – это нелинейная функция, применяемая к выходу линейной части нейрона ($z$) для получения его итоговой активации ($a$).
2. **Зачем Нужны Нелинейные Активации?**
    * **Ключевая Роль:** Если бы все функции активации в сети были линейными ($f(z) = cz$ или $f(z)=z$), то вся многослойная сеть, независимо от ее глубины, была бы эквивалентна *одной* линейной модели (одному слою). Она не смогла бы выучивать сложные, **нелинейные зависимости** в данных, что является основной силой нейронных сетей. Нелинейные активации "ломают" линейность и позволяют сети аппроксимировать сложные функции.
3. **Распространенные Функции Активации:**
    * **Sigmoid (Сигмоида):**
        * Формула: $\sigma(z) = \frac{1}{1 + e^{-z}}$
        * Диапазон: (0, 1).
        * Применение: Раньше часто использовалась в скрытых слоях, сейчас – в основном в **выходном слое для бинарной классификации** (для предсказания вероятности).
        * Проблемы:
            * **Насыщение (Saturation):** При больших $|z|$ производная $\sigma'(z)$ становится очень близкой к нулю. Это приводит к **затуханию градиентов (Vanishing Gradients)** при обратном распространении ошибки, замедляя или останавливая обучение глубоких сетей.
            * **Не центрирована около нуля:** Выходы всегда положительны. Это может замедлять сходимость GD.
    * **Tanh (Гиперболический Тангенс):**
        * Формула: $\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} = 2\sigma(2z) - 1$
        * Диапазон: (-1, 1).
        * Применение: Иногда используется в скрытых слоях, часто лучше сигмоиды, так как **центрирована около нуля**.
        * Проблемы: Также страдает от **насыщения и затухания градиентов**.
    * **ReLU (Rectified Linear Unit):**
        * Формула: $ReLU(z) = \max(0, z)$
        * Диапазон: [0, $+\infty$).
        * Применение: **Стандарт де-факто для скрытых слоев** во многих архитектурах (MLP, CNN).
        * Преимущества:
            * **Вычислительно эффективна.**
            * **Не насыщается** при $z>0$, что решает проблему затухания градиента в этой области. Ускоряет сходимость GD.
        * Проблемы:
            * **"Умирающий ReLU" (Dying ReLU):** Если нейрон постоянно получает на вход $z \le 0$, его градиент становится равным 0, и веса этого нейрона перестают обновляться. Нейрон "умирает".
            * **Не центрирована около нуля.**
    * **Leaky ReLU (и его варианты PReLU, RReLU):**
        * Формула: $LeakyReLU(z) = \max(\alpha z, z)$, где $\alpha$ - малый коэффициент (например, 0.01). В PReLU $\alpha$ обучается.
        * Цель: Решить проблему "умирающего ReLU", позволяя небольшой ненулевой градиент при $z < 0$.
    * **ELU (Exponential Linear Unit):**
        * Формула: $ELU(z) = \begin{cases} z & \text{if } z > 0 \\ \alpha (e^z - 1) & \text{if } z \le 0 \end{cases}$ ($\alpha > 0$).
        * Цель: Преимущества ReLU + выходы могут быть отрицательными (ближе к центрированным) + гладкость в нуле. Вычислительно дороже.
    * **Softmax:**
        * Формула: $\text{Softmax}(z_k) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}}$ (где $z = (z_1, ..., z_K)$ - вектор логитов для K классов).
        * Применение: Используется **только в выходном слое для мультиклассовой классификации**. Преобразует вектор логитов в вектор вероятностей, сумма которых равна 1.

#### 1.3 Архитектура Сети (MLP)

1. **Слои:** Нейроны организуются в слои.
    * **Входной слой (Input Layer):** Не содержит нейронов в вычислительном смысле, просто передает входные признаки $x$ первому скрытому слою.
    * **Скрытые слои (Hidden Layers):** Один или несколько слоев нейронов между входным и выходным. Выполняют основные вычисления и преобразования признаков.
    * **Выходной слой (Output Layer):** Последний слой нейронов, выдающий финальный результат (например, вероятность для классификации, значение для регрессии). Функция активации выходного слоя зависит от задачи (Sigmoid/Softmax для классификации, линейная для регрессии).
2. **Полносвязный Слой (Dense / Fully Connected Layer):** Слой, в котором *каждый* нейрон связан со *всеми* нейронами (или входами) предыдущего слоя. MLP состоит из таких слоев.

### Часть 2: Обучение Нейронной Сети

#### 2.1 Общий Цикл Обучения

Обучение нейронной сети – это итеративный процесс, обычно с использованием вариаций градиентного спуска, который включает следующие шаги:

1. **Инициализация Весов:** Задать начальные (обычно малые случайные) значения для всех весов $w$ и смещений $b$ в сети.
2. **Цикл по Эпохам:** (Эпоха - один полный проход по всем обучающим данным).
    * **Цикл по Мини-Батчам:** (Данные делятся на небольшие группы - мини-батчи).
        * **а) Прямой Проход (Forward Pass):** Подать входные данные мини-батча ($\mathbf{X}_B$) на вход сети и вычислить активации слой за слоем до получения выходных предсказаний ($\hat{\mathbf{Y}}_B$).
        * **б) Вычисление Функции Потерь (Loss Calculation):** Сравнить предсказания ($\hat{\mathbf{Y}}_B$) с истинными значениями ($\mathbf{Y}_B$) с помощью функции потерь $J(W)$ (где $W$ - все параметры сети) и вычислить ее значение для батча.
        * **в) Обратный Проход (Backward Pass / Backpropagation):** Вычислить **градиент** функции потерь $\nabla J(W)$ по *всем* обучаемым параметрам сети (весам и смещениям). Это делается эффективно с помощью алгоритма обратного распространения ошибки.
        * **г) Обновление Весов (Weight Update):** Скорректировать параметры сети, сделав шаг в направлении, противоположном градиенту, с использованием выбранного алгоритма оптимизации (например, SGD, Adam) и скорости обучения $\alpha$.
            $W := W - \alpha \nabla J(W)$ (упрощенно)
3. **Оценка и Остановка:** Периодически оценивать производительность модели на валидационной выборке. Остановить обучение по критерию (число эпох, отсутствие улучшения на валидации - Early Stopping).

#### 2.2 Функция Потерь (Loss Function)

1. **Определение:** Функция, измеряющая несоответствие между предсказаниями сети $\hat{y}$ и истинными значениями $y$. Цель обучения - минимизировать эту функцию.
2. **Выбор Функции Потерь Зависит от Задачи:**
    * **Регрессия:**
        * **MSE (Mean Squared Error):** $J = \frac{1}{m} \sum (\hat{y}^{(i)} - y^{(i)})^2$. Стандартный выбор.
        * **MAE (Mean Absolute Error):** $J = \frac{1}{m} \sum |\hat{y}^{(i)} - y^{(i)}|$. Менее чувствительна к выбросам.
    * **Бинарная Классификация (Выход - Sigmoid):**
        * **Binary Cross-Entropy (Log Loss):** $J = -\frac{1}{m} \sum [ y^{(i)} \log(\hat{p}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{p}^{(i)}) ]$. Стандартный выбор.
    * **Мультиклассовая Классификация (Выход - Softmax):**
        * **Categorical Cross-Entropy:** $J = -\frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{K} y_k^{(i)} \log(\hat{p}_k^{(i)})$. Стандартный выбор ($y_k^{(i)}$ - one-hot encoding истины).

#### 2.3 Обратное Распространение Ошибки (Backpropagation)

1. **Цель:** **Эффективно вычислить градиент $\nabla J(W)$** функции потерь $J$ по всем параметрам $W$ сети (всем весам и смещениям во всех слоях).
2. **Не То же Самое, что Градиентный Спуск!** Backpropagation – это *алгоритм расчета градиента*. Градиентный спуск – это *алгоритм оптимизации*, который *использует* этот градиент для обновления весов.
3. **Основная Идея: Применение Цепного Правила (Chain Rule) Дифференцирования.**
    * Функция потерь $J$ зависит от выходов последнего слоя. Выходы последнего слоя зависят от его весов и активаций предыдущего слоя. Активации предыдущего слоя зависят от его весов и активаций еще более раннего слоя, и так далее, до входных данных.
    * Чтобы найти производную $J$ по весу $w_{jk}^{[l]}$ (вес, соединяющий нейрон $k$ слоя $l-1$ с нейроном $j$ слоя $l$), нужно последовательно применить цепное правило, двигаясь *от конца сети к началу*.
4. **Концептуальные Шаги (для одного примера):**
    * **Forward Pass:** Посчитать все активации $a^{[l]}$ и преактивации $z^{[l]}$ для всех слоев $l$ от 1 до $L$ (выходной слой).
    * **Backward Pass:**
        * **Шаг 1 (Выходной слой L):** Посчитать "ошибку" $\delta^{[L]} = \frac{\partial J}{\partial z^{[L]}}$. Это зависит от функции потерь и активации выходного слоя. Например, для MSE и линейной активации $\delta^{[L]} = (\hat{y} - y)$. Для CrossEntropy и Softmax $\delta^{[L]} = (\hat{p} - y)$ (где $y$ - one-hot вектор).
        * **Шаг 2 (Распространение ошибки назад):** Для каждого слоя $l = L-1, ..., 1$:
            * Вычислить "ошибку" слоя $l$: $\delta^{[l]} = \frac{\partial J}{\partial z^{[l]}} = (\text{ошибка следующего слоя } \delta^{[l+1]}) \times (\text{веса слоя } W^{[l+1]}) \times (\text{производная активации } f^{[l]'}(z^{[l]}))$ (упрощенно, используется матричное умножение и поэлементное умножение Адамара).
        * **Шаг 3 (Расчет градиентов по весам):** Для каждого слоя $l$:
            * Градиент по весам $W^{[l]}$: $\frac{\partial J}{\partial W^{[l]}} = (\text{ошибка этого слоя } \delta^{[l]}) \times (\text{активации предыдущего слоя } a^{[l-1]})$ (упрощенно).
            * Градиент по смещениям $b^{[l]}$: $\frac{\partial J}{\partial b^{[l]}} = \delta^{[l]}$ (упрощенно).
5. **Результат:** После одного обратного прохода мы имеем градиенты $\frac{\partial J}{\partial W^{[l]}}$ и $\frac{\partial J}{\partial b^{[l]}}$ для всех слоев $l$. Эти градиенты затем используются для обновления параметров с помощью оптимизатора (GD, Adam и т.д.).

#### 2.4 Оптимизаторы (Помимо Ванильного GD)

1. **Проблемы Ванильного GD/SGD:**
    * Может медленно сходиться в "оврагах" (узких долинах функции потерь).
    * Может застревать в локальных минимумах или седловых точках (для невыпуклых функций потерь NN).
    * Требует ручного подбора скорости обучения $\alpha$.
    * Одна и та же $\alpha$ применяется ко всем параметрам, что не всегда оптимально.
2. **Идеи Улучшенных Оптимизаторов:**
    * **Momentum:** Добавляет "инерцию" к обновлению весов. Учитывает градиенты с предыдущих шагов, помогая быстрее двигаться по пологим склонам и сглаживая колебания.
        * $v_t = \beta v_{t-1} + (1-\beta) \nabla J(W_t)$ (скользящее среднее градиентов)
        * $W_{t+1} = W_t - \alpha v_t$ ($\beta$ обычно ~0.9)
    * **AdaGrad:** Адаптирует скорость обучения *для каждого параметра* индивидуально. Уменьшает $\alpha$ для параметров, по которым градиенты часто большие, и увеличивает для параметров с малыми градиентами. Проблема: $\alpha$ может слишком быстро уменьшиться до нуля.
    * **RMSProp:** Похож на AdaGrad, но использует скользящее среднее *квадратов* градиентов, чтобы предотвратить слишком быстрое затухание $\alpha$.
    * **Adam (Adaptive Moment Estimation):** **Очень популярный и часто используемый по умолчанию.** Комбинирует идеи Momentum (оценка первого момента - среднего градиента) и RMSProp (оценка второго момента - среднего квадрата градиента) для адаптации $\alpha$ для каждого параметра.
        * (Формулы сложнее, включают коррекцию смещения на начальных этапах).
3. **Сходимость:** Для невыпуклых функций потерь нейронных сетей **нет гарантии** сходимости к *глобальному* минимуму. Однако на практике GD и его варианты часто находят "достаточно хорошие" локальные минимумы, которые обеспечивают хорошую производительность модели.

### Часть 3: Регуляризация и Стабилизация Обучения

#### 3.1 Проблемы Затухания и Взрыва Градиентов

1. **Описание:** При обучении глубоких сетей градиенты, распространяемые назад (через Backpropagation), могут либо становиться экспоненциально **маленькими (Vanishing Gradients)**, либо экспоненциально **большими (Exploding Gradients)**.
2. **Причины:** Многократное умножение на числа < 1 (для затухания) или > 1 (для взрыва) при проходе через слои (особенно на производные активаций и веса). Глубина сети усугубляет эффект.
3. **Последствия:**
    * **Затухание:** Ранние слои сети обучаются очень медленно или совсем не обучаются, так как до них "не доходят" градиенты.
    * **Взрыв:** Приводит к очень большим обновлениям весов, нестабильности обучения (Loss может стать NaN).
4. **Методы Борьбы:**
    * **Выбор Функций Активации:** Использовать активации, не склонные к насыщению (ReLU и его варианты) вместо Sigmoid/Tanh.
    * **Инициализация Весов:** Использовать "умные" стратегии (Xavier/He), чтобы поддерживать разумный масштаб активаций и градиентов.
    * **Batch Normalization:** Помогает стабилизировать распределение активаций и градиентов.
    * **Residual Connections (ResNets):** Создают "короткие пути" для градиента, позволяя ему обходить слои и не затухать.
    * **Gradient Clipping:** Если норма (длина) вектора градиента превышает заданный порог, его масштабируют (уменьшают) до этого порога. Предотвращает взрыв градиентов.

#### 3.2 Инициализация Весов

1. **Почему Не Нули?** Если все веса инициализировать нулями, то все нейроны в слое будут вычислять одно и то же, и их градиенты будут одинаковыми. Симметрия не нарушится, и сеть не сможет обучиться разным признакам. Смещение ($b$) можно инициализировать нулями.
2. **Цель "Умной" Инициализации:** Выбрать начальные веса так, чтобы активации и градиенты на разных слоях имели примерно одинаковую (и разумную) дисперсию. Это предотвращает слишком быстрое затухание/взрыв градиентов и активаций на начальных этапах.
3. **Основные Методы:**
    * **Xavier / Glorot Initialization:** (Хорошо работает с Sigmoid/Tanh). Масштаб случайных весов подбирается на основе числа нейронов во входном ($n_{in}$) и выходном ($n_{out}$) слоях. Например, веса из $\mathcal{N}(0, \sigma^2)$ с $\sigma^2 = 2 / (n_{in} + n_{out})$.
    * **Kaiming / He Initialization:** (Хорошо работает с ReLU и его вариантами). Учитывает, что ReLU "обнуляет" половину активаций. Масштаб подбирается обычно на основе $n_{in}$. Например, веса из $\mathcal{N}(0, \sigma^2)$ с $\sigma^2 = 2 / n_{in}$.

#### 3.3 Batch Normalization (BN)

1. **Определение:** Техника стабилизации и ускорения обучения путем нормализации входов *каждого* слоя *по текущему мини-батчу*.
2. **Механизм (для активаций $z$ слоя перед нелинейностью):**
    * **Шаг 1: Вычисление среднего и дисперсии по мини-батчу:** Для каждой фичи $k$ в $z$ считаем среднее $\mu_{B,k}$ и дисперсию $\sigma^2_{B,k}$ по объектам текущего мини-батча $B$.
    * **Шаг 2: Нормализация:** Нормализуем каждую фичу: $\hat{z}_{k} = \frac{z_{k} - \mu_{B,k}}{\sqrt{\sigma^2_{B,k} + \epsilon}}$ (где $\epsilon$ - малая константа для стабильности).
    * **Шаг 3: Масштабирование и Сдвиг:** Преобразуем нормализованное значение с помощью **обучаемых** параметров $\gamma_k$ (масштаб) и $\beta_k$ (сдвиг), специфичных для каждой фичи $k$: $BN(z_k) = \gamma_k \hat{z}_{k} + \beta_k$.
3. **Зачем Шаг 3?** Просто нормализация ($\mu=0, \sigma=1$) может ограничивать выразительную способность слоя. Обучаемые $\gamma$ и $\beta$ позволяют сети самой решать, какой масштаб и сдвиг оптимальны (вплоть до восстановления исходного распределения, если это нужно).
4. **Internal Covariate Shift (ICS):** Это изменение распределения активаций слоя во время обучения из-за обновления весов предыдущих слоев. BN уменьшает ICS, стандартизируя входы слоя, что делает обучение более стабильным и позволяет использовать более высокие скорости обучения.
5. **Разница Train / Inference:**
    * **На Обучении (Train):** $\mu_B$ и $\sigma^2_B$ считаются по текущему мини-батчу. Также обновляются скользящие средние ($\mu_{pop}, \sigma^2_{pop}$) по всем батчам. Веса $\gamma, \beta$ обучаются через Backprop.
    * **На Тестировании (Inference):** Используются **популяционные** среднее и дисперсия ($\mu_{pop}, \sigma^2_{pop}$), накопленные во время обучения (или оцененные на всей выборке), а также обученные $\gamma, \beta$. Нормализация идет по этим фиксированным значениям, а не по батчу.

#### 3.4 Dropout

1. **Определение:** Техника регуляризации для борьбы с переобучением в нейронных сетях.
2. **Механизм (Inverted Dropout - стандартный):**
    * **На Обучении (Train):** Для каждого нейрона в слое (кроме выходного) с вероятностью $p$ (гиперпараметр, например, 0.5) его выход **обнуляется** на данной итерации (для данного мини-батча). Выходы оставшихся "активных" нейронов **масштабируются (делятся)** на $(1-p)$.
    * **На Тестировании (Inference):** Dropout **отключается**. Все нейроны используются со своими обученными весами (никакого масштабирования не нужно, так как оно было сделано на этапе обучения).
3. **Почему Работает?**
    * **Предотвращает Ко-адаптацию:** Нейроны не могут слишком сильно полагаться на выходы конкретных других нейронов, так как те могут быть случайно "выключены". Это заставляет их выучивать более робастные и независимые признаки.
    * **Ансамбль Подсетей:** Dropout можно рассматривать как обучение огромного количества разных подсетей (с разным набором "включенных" нейронов) с общими весами. На этапе инференса использование всех нейронов аппроксимирует усреднение предсказаний этого ансамбля.

#### 3.5 Residual Connections (ResNets)

1. **Проблема:** Обучение очень глубоких сетей затруднено из-за затухания градиентов. Добавление новых слоев может даже ухудшать производительность (degradation problem).
2. **Идея:** Добавить "обходные пути" (skip connections), которые позволяют сигналу (и градиенту) проходить напрямую через несколько слоев.
3. **Структура Residual Блока:** Выход блока вычисляется как $H(x) = F(x) + x$.
    * $x$: вход блока.
    * $F(x)$: Нелинейное преобразование в блоке (например, несколько слоев Conv-BN-ReLU).
    * $+$: Поэлементное сложение (требует совпадения размерностей $F(x)$ и $x$, иногда используются проекции).
4. **Как Помогает Градиенту:** Производная по входу $x$ равна $\frac{\partial H(x)}{\partial x} = \frac{\partial F(x)}{\partial x} + 1$. Член "+1" гарантирует, что градиент может проходить назад через блок без затухания, даже если производная $\frac{\partial F(x)}{\partial x}$ мала. Это позволяет строить и эффективно обучать гораздо более глубокие сети.

### Часть 4: Основы CNN (для ответа на вопрос о параметрах)

1. **Сверточный Слой (Convolutional Layer):**
    * **Идея:** Применяет **фильтры (ядра)** к локальным областям входного изображения (или карты признаков). Фильтры выявляют пространственные паттерны (грани, текстуры и т.д.).
    * **Общие Веса (Weight Sharing):** Один и тот же фильтр применяется ко *всем* позициям входа, что резко сокращает число параметров по сравнению с полносвязным слоем и делает модель инвариантной к сдвигу.
    * **Параметры Фильтра:** Каждый фильтр имеет размер (например, 3x3 или 5x5), глубину (равную числу каналов входа, например, 3 для RGB) и обычно свой bias.
    * **Число Обучаемых Параметров в Слое:**
        * Пусть размер фильтра $F \times F$, число входных каналов $C_{in}$, число фильтров (равно числу выходных каналов $C_{out}$) равно $K$.
        * Параметры одного фильтра: $F \times F \times C_{in}$ весов + 1 bias.
        * Всего параметров в слое: $(F \times F \times C_{in} + 1) \times K$
2. **Слой Пулинга (Pooling Layer):**
    * **Идея:** Уменьшает пространственный размер карты признаков (downsampling), делая представление более компактным и устойчивым к небольшим сдвигам/деформациям.
    * **Виды:** Max Pooling (берет максимум в окне), Average Pooling (берет среднее).
    * **Нет Обучаемых Параметров.**
