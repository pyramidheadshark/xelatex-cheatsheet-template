## Углубленный Конспект: Детекция и Борьба с Переобучением (+ Регуляризация)

**Цель секции на интервью:** Проверить понимание кандидатом одной из фундаментальных проблем ML – переобучения. Оценивается способность диагностировать проблему, знание основных методов борьбы (включая регуляризацию), умение объяснить их принцип работы и записать ключевые формулы.

---

### 1. Основы: Переобучение (Overfitting) и Недообучение (Underfitting)

* **Ключевая Цель ML:** Построить модель, которая хорошо **обобщается** (generalizes), то есть показывает низкую ошибку на **новых, невиданных ранее данных**, а не только на тех, на которых обучалась.
* **Недообучение (Underfitting):**
  * **Определение:** Модель слишком проста, чтобы уловить основные закономерности в данных.
  * **Проявление:** Модель показывает **высокую ошибку** как на **обучающей (Train)**, так и на **валидационной/тестовой (Validation/Test)** выборках.
  * **Связь с Bias-Variance:** Характеризуется **высоким Bias** (систематическая ошибка, модель не способна описать данные) и **низким Variance** (предсказания стабильны, но неверны).
* **Переобучение (Overfitting):**
  * **Определение:** Модель слишком сложная и начинает "запоминать" обучающие данные, включая случайный шум и выбросы, вместо того чтобы улавливать общую закономерность.
  * **Проявление:** Модель показывает **очень низкую ошибку** на **обучающей** выборке, но **значительно более высокую ошибку** на **валидационной/тестовой** выборке.
  * **Связь с Bias-Variance:** Характеризуется **низким Bias** (на обучающих данных модель точна) и **высоким Variance** (модель очень чувствительна к конкретной обучающей выборке, ее предсказания сильно меняются при смене данных).

### 2. Детекция Переобучения

* **Основной Инструмент:** Сравнение метрик качества (или функции потерь) на **обучающей** и **валидационной** выборках в процессе обучения или после него.
  * **Признак Переобучения:** Значительный разрыв (gap) между качеством на трейне и валидации (трейн намного лучше валидации).
* **Визуализация: Кривые Обучения (Learning Curves):**
  * **Определение:** Графики зависимости метрики качества (или ошибки) от некоторого параметра, характеризующего процесс обучения (например, размер обучающей выборки, номер эпохи/итерации, параметр сложности модели). Строятся две кривые: одна для обучающей выборки, другая – для валидационной.
  * **Анализ кривых (по оси X - номер эпохи/итерации):**
    * **Нормальное обучение:** Обе кривые (Train, Validation) сходятся к низкому уровню ошибки, разрыв между ними небольшой и стабильный.
    * **Переобучение:** Кривая Train уходит к очень низкой ошибке, кривая Validation выходит на плато на более высоком уровне ошибки или даже начинает расти. Разрыв между кривыми большой и/или растет.
    * **Недообучение:** Обе кривые сходятся к высокому уровню ошибки, разрыв между ними маленький.
  * *(На интервью могут попросить нарисовать эти кривые и объяснить их).*

### 3. Методы Борьбы с Переобучением (Общие Стратегии)

* **Цель:** Снизить сложность модели или ее чувствительность к обучающим данным, чтобы улучшить обобщающую способность (уменьшить Variance, возможно, немного увеличив Bias).
* **Основные Методы:**
    1. **Увеличение Объема Обучающих Данных:**
        * **Принцип:** Больше разнообразных данных помогает модели выучить более устойчивые закономерности и "усреднить" влияние шума.
        * **Когда помогает:** В первую очередь при переобучении (High Variance). Если модель недообучена (High Bias), добавление данных, скорее всего, не поможет.
    2. **Упрощение Модели:**
        * **Принцип:** Использовать модель с меньшим числом параметров или меньшей гибкостью.
        * **Примеры:**
            * Линейные модели: Уменьшить число признаков (Feature Selection).
            * Деревья решений: Уменьшить максимальную глубину (`max_depth`), увеличить минимальное число объектов для разделения/в листе (`min_samples_split`, `min_samples_leaf`).
            * Нейронные сети: Уменьшить число слоев или нейронов в слоях.
    3. **Отбор Признаков (Feature Selection) / Инженерия Признаков (Feature Engineering):**
        * **Принцип:** Удалить неинформативные, избыточные или зашумленные признаки, которые могут вводить модель в заблуждение и способствовать переобучению. Создать более качественные признаки.
    4. **Ранняя Остановка (Early Stopping):**
        * **Принцип:** В процессе итеративного обучения (например, GD в нейросетях или бустинге) отслеживать метрику качества на **валидационной** выборке. Остановить обучение в тот момент, когда метрика на валидации перестает улучшаться (или начинает ухудшаться), даже если метрика на обучении продолжает падать.
        * **Требует:** Наличия отдельной валидационной выборки.
    5. **Ансамблирование (Ensembling):**
        * **Принцип:** Комбинирование предсказаний нескольких моделей.
        * **Примеры:**
            * **Bagging (e.g., Random Forest):** Усреднение предсказаний множества независимо обученных моделей (обычно глубоких деревьев с высоким Variance) **снижает Variance** итогового ансамбля.
            * **Boosting (e.g., Gradient Boosting):** Последовательное построение моделей, исправляющих ошибки предыдущих, часто позволяет **снизить Bias** (но может и переобучиться, если не контролировать).
    6. **Регуляризация:** (Рассматривается подробно далее)
        * **Принцип:** Добавление штрафа за сложность модели (обычно за величину весов) в функцию потерь.

### 4. Регуляризация (Подробно)

* **Определение:** Техника, направленная на снижение сложности модели и предотвращение переобучения путем добавления к основной функции потерь $J_{original}(w)$ штрафного слагаемого $\text{Penalty}(w)$, которое зависит от весов модели $w$.
* **Общая Формула:** $J_{reg}(w) = J_{original}(w) + \text{Penalty}(w)$
* **Цель Штрафа:** Заставить модель использовать **меньшие значения весов** $w_j$. Интуиция: модели с большими весами более сложны и чувствительны к малым изменениям входных признаков, что характерно для переобучения.
* **Важно:** Свободный член $w_0$ (bias/intercept) обычно **не регуляризуется**, так как он отвечает за общий сдвиг и не влияет на "крутизну" зависимости от признаков. Суммирование в штрафах ниже идет с $j=1$ до $n$.
* **Гиперпараметр $\lambda$ (Лямбда):**
  * **Определение:** Неотрицательный коэффициент ($\lambda \ge 0$), контролирующий **силу регуляризации**.
  * $\lambda = 0$: Нет регуляризации.
  * $\lambda > 0$: Чем больше $\lambda$, тем сильнее штраф за веса, тем проще становится модель (выше Bias, ниже Variance).
  * **Подбор $\lambda$:** Осуществляется с помощью **кросс-валидации**.

#### 4.1. L2 Регуляризация (Гребневая / Ridge)

* **Формула Штрафа:** Квадрат L2-нормы вектора весов (без $w_0$).
    $\text{Penalty}_{L2}(w) = \frac{\lambda}{2m} \sum_{j=1}^{n} w_j^2$
    *(Множитель $\frac{1}{2m}$ для удобства и согласованности, ключевое – $\lambda \sum w_j^2$).*
* **Функция Потерь (Пример для MSE):**
    $J_{Ridge}(w) = \underbrace{\frac{1}{2m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2}_{J_{original}} + \underbrace{\frac{\lambda}{2m} \sum_{j=1}^{n} w_j^2}_{\text{L2 Penalty}}$
* **Эффект ("Shrinkage" / Сжатие):**
  * Штрафует большие веса квадратично.
  * "Сжимает" веса по направлению к нулю, но **редко обнуляет** их полностью.
  * Делает модель "глаже", менее чувствительной к входам.
  * Помогает при **мультиколлинеарности** (стабилизирует решение).
  * Уменьшает **Variance**, увеличивает **Bias**.
* **Градиентный Спуск с L2:**
  * Производная L2 штрафа по $w_k$ (для $k \ge 1$): $\frac{\partial (\text{Penalty}_{L2})}{\partial w_k} = \frac{\lambda}{m} w_k$.
  * **Обновление весов ($k=1, ..., n$):**
        $w_k := w_k - \alpha \left( \frac{\partial J_{original}}{\partial w_k} + \frac{\lambda}{m} w_k \right)$
        $w_k := w_k \underbrace{(1 - \alpha \frac{\lambda}{m})}_{\text{Weight Decay}} - \alpha \frac{\partial J_{original}}{\partial w_k}$
        *(Вес $w_k$ на каждом шаге немного уменьшается (decay) перед основным градиентным шагом).*
  * **Обновление $w_0$:** Происходит без члена регуляризации: $w_0 := w_0 - \alpha \frac{\partial J_{original}}{\partial w_0}$.
* **Геометрическая Интерпретация:** Поиск минимума $J_{original}$ при ограничении $\sum w_j^2 \le C$ (веса внутри сферы/круга).

#### 4.2. L1 Регуляризация (Lasso)

* **Формула Штрафа:** L1-норма вектора весов (без $w_0$), умноженная на коэффициент.
    $\text{Penalty}_{L1}(w) = \frac{\lambda}{m} \sum_{j=1}^{n} |w_j|$
* **Функция Потерь (Пример для MSE):**
    $J_{Lasso}(w) = \underbrace{\frac{1}{2m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2}_{J_{original}} + \underbrace{\frac{\lambda}{m} \sum_{j=1}^{n} |w_j|}_{\text{L1 Penalty}}$
* **Эффект ("Sparsity" / Разреженность):**
  * Штрафует веса линейно по их модулю.
  * Имеет свойство **обнулять некоторые веса** ($w_j=0$).
  * Выполняет **автоматический отбор признаков**.
  * Приводит к **разреженным моделям** (много нулевых весов).
  * Уменьшает **Variance**, увеличивает **Bias**.
* **Градиентный Спуск с L1:**
  * Проблема: $|w_j|$ не дифференцируема в $w_j=0$.
  * Решение: Используются субградиентные методы, проксимальные методы (ISTA, FISTA) или координатный спуск.
  * **Субградиент $|w_j|$:** $\text{sign}(w_j) = \begin{cases} +1, & w_j > 0 \\ -1, & w_j < 0 \\ \in [-1, 1], & w_j = 0 \end{cases}$
  * **Обновление весов (Концептуально, с субградиентом, $k=1, ..., n$):**
        $w_k := w_k - \alpha \left( \frac{\partial J_{original}}{\partial w_k} + \frac{\lambda}{m} \text{sign}(w_k) \right)$
        *(Штраф $\frac{\lambda}{m} \text{sign}(w_k)$ "тянет" вес к нулю с постоянной силой, независимо от величины веса. Это и приводит к обнулению, в отличие от L2, где сила уменьшается при приближении к нулю).*
  * **Обновление $w_0$:** Без регуляризации.
* **Геометрическая Интерпретация:** Поиск минимума $J_{original}$ при ограничении $\sum |w_j| \le C$ (веса внутри ромба/октаэдра). Минимум часто достигается в "углах", где некоторые координаты равны нулю.

#### 4.3. Elastic Net

* **Определение:** Комбинация L1 и L2 регуляризации.
* **Формула Штрафа:**
    $\text{Penalty}_{ElasticNet}(w) = \lambda_1 \sum_{j=1}^{n} |w_j| + \lambda_2 \sum_{j=1}^{n} w_j^2$
    (Или используется один $\lambda$ и параметр смешивания $\alpha \in$: $\lambda (\alpha ||w||_1 + (1-\alpha) \frac{1}{2} ||w||_2^2)$ ).
* **Цель:** Получить преимущества обоих методов: отбор признаков от L1 и стабильность/группировку признаков от L2. Полезна при большом числе сильно коррелирующих признаков.

#### 4.4. Важность Масштабирования Признаков перед Регуляризацией

* **Проблема:** Регуляризация штрафует абсолютные значения весов $w_j$. Если признаки $x_j$ имеют разный масштаб, то и их веса $w_j$ будут иметь разный масштаб, даже если признаки одинаково важны. Штраф будет несправедливо применен.
* **Решение:** **Обязательно** масштабировать признаки (привести к сравнимому масштабу) **до** применения регуляризации.
  * **StandardScaler:** $x' = (x - \mu) / \sigma$. (Среднее 0, ст. откл. 1).
  * **MinMaxScaler:** $x' = (x - \min) / (\max - \min)$. (Диапазон).
  * **Важно:** Параметры скейлера (mean/std или min/max) вычисляются (fit) **только** на обучающей выборке и затем применяются (transform) ко всем данным (train, validation, test).

### 5. Регуляризация в Других Моделях (Кратко)

* **Деревья Решений:** Регуляризация достигается ограничением сложности дерева: `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_leaf_nodes`, `ccp_alpha` (Cost Complexity Pruning).
* **Random Forest:** Регуляризация происходит за счет контроля сложности *каждого отдельного дерева* (см. выше) и самого принципа **бэггинга**, который снижает Variance.
* **Gradient Boosting:** Регуляризация достигается через:
  * Контроль сложности базовых деревьев.
  * **Learning Rate ($\eta$):** Меньший LR замедляет обучение и снижает риск переобучения.
  * **Subsampling:** Использование части данных/признаков для построения каждого дерева.
  * **Явная регуляризация (в XGBoost):** L1/L2 штрафы на **значения в листьях** деревьев.
* **Нейронные Сети:** L1/L2 регуляризация на веса слоев, **Dropout**, Batch Normalization (имеет регуляризующий эффект), Early Stopping, Data Augmentation.

### 6. Связь Регуляризации с Bias-Variance Tradeoff

* **Ключевая Идея:** Регуляризация – это явный инструмент управления дилеммой смещения-разброса.
* **Механизм:** Добавляя штраф за сложность (большие веса), мы **намеренно упрощаем модель**.
* **Эффект:**
  * Увеличение коэффициента регуляризации $\lambda$ $\implies$ Модель становится проще $\implies$ **Bias увеличивается** (модель может хуже описывать сложные зависимости даже на трейне).
  * Увеличение коэффициента регуляризации $\lambda$ $\implies$ Модель становится менее чувствительной к шуму и особенностям трейна $\implies$ **Variance уменьшается** (разброс предсказаний на разных выборках снижается, переобучение уменьшается).
* **Цель:** Найти такое $\lambda$ (с помощью CV), которое дает оптимальный баланс Bias и Variance, минимизируя ошибку на **невиданных данных**.
