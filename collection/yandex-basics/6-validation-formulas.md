# Детальный Вывод Формул и Концепций: Валидация и Оценка Модели

*(Используем обозначения: $m$ - число объектов, $n$ - число признаков, $x^{(i)}$ - вектор признаков $i$-го объекта, $y^{(i)}$ - истинное значение/класс $i$-го объекта, $K$ - число фолдов в CV, $M_k$ - метрика на $k$-м фолде, $\bar{M}$ - средняя метрика по CV, $\lambda$ - коэффициент в SMOTE, $w_{y^{(i)}}$ - вес класса $y^{(i)}$, $\hat{p}^{(i)}$ - предсказанная вероятность).*

## 1. K-Fold Cross-Validation: Оценка Метрики

**Цель:** Получить более надежную оценку качества модели, усреднив результаты по нескольким разбиениям данных.

**Шаг 1: Разбиение Данных**
Данные (Train+Validation) делятся на $K$ непересекающихся фолдов.

**Шаг 2: Итеративное Обучение и Оценка**
Для каждого фолда $k$ (от 1 до $K$):

1. Обучить модель на данных из $K-1$ фолдов (всех, кроме $k$-го).
2. Рассчитать метрику качества $M_k$ на $k$-м (валидационном) фолде.

**Шаг 3: Усреднение Результатов**
Итоговая оценка метрики ($\bar{M}$) и ее стандартное отклонение ($std(M)$) рассчитываются как:
$$
\boxed{
\bar{M} = \frac{1}{K} \sum_{k=1}^{K} M_k
}
$$
$$
\boxed{
std(M) = \sqrt{\frac{1}{K-1} \sum_{k=1}^{K} (M_k - \bar{M})^2} \quad (\text{Выборочное ст. отклонение})
}
$$

* **Объяснение:** $\bar{M}$ дает среднюю оценку производительности модели. $std(M)$ показывает, насколько стабильна эта оценка при разных разбиениях данных (низкое значение $std(M)$ предпочтительнее).

## 2. Масштабирование Признаков (Препроцессинг)

**Цель:** Привести признаки к одному масштабу, что важно для алгоритмов, чувствительных к масштабу (GD, KNN, модели с регуляризацией). `fit` делается **только** на обучающих данных (train), `transform` применяется ко всем (train, val, test).

**2.1 StandardScaler**
Приводит данные к нулевому среднему ($\mu=0$) и единичному стандартному отклонению ($\sigma=1$).

**Шаг 1: Вычисление $\mu_j$ и $\sigma_j$ (на Train Set)**
Для каждого признака $j$ (от 1 до $n$) вычислить среднее $\mu_j$ и стандартное отклонение $\sigma_j$ **только по обучающей выборке**:
$$
\mu_j = \frac{1}{m_{train}} \sum_{i \in train} x_j^{(i)}
$$
$$
\sigma_j = \sqrt{\frac{1}{m_{train}-1} \sum_{i \in train} (x_j^{(i)} - \mu_j)^2} \quad (\text{Если } \sigma_j = 0, \text{ использовать } 1)
$$

**Шаг 2: Применение Масштабирования (Transform)**
Для каждого объекта $i$ и каждого признака $j$:
$$
\boxed{
x_{j, scaled}^{(i)} = \frac{x_j^{(i)} - \mu_j}{\sigma_j}
}
$$

* **Объяснение:** Из каждого значения вычитается среднее по признаку и делится на стандартное отклонение по признаку (вычисленные на трейне).

**2.2 MinMaxScaler**
Приводит данные к заданному диапазону, обычно [0, 1].

**Шаг 1: Вычисление $\min_j$ и $\max_j$ (на Train Set)**
Для каждого признака $j$ (от 1 до $n$) найти минимальное $\min_j$ и максимальное $\max_j$ значение **только по обучающей выборке**:
$$
\min_j = \min_{i \in train} (x_j^{(i)})
$$
$$
\max_j = \max_{i \in train} (x_j^{(i)})
$$

**Шаг 2: Применение Масштабирования (Transform)**
Для каждого объекта $i$ и каждого признака $j$:
$$
\boxed{
x_{j, scaled}^{(i)} = \frac{x_j^{(i)} - \min_j}{\max_j - \min_j} \quad (\text{Если } \max_j = \min_j, \text{ результат 0 или 0.5})
}
$$

* **Объяснение:** Значение масштабируется пропорционально его положению между минимумом и максимумом (вычисленными на трейне).

## 3. SMOTE (Synthetic Minority Over-sampling Technique)

**Цель:** Сбалансировать классы путем генерации синтетических примеров минорного класса. Применяется **только** к обучающей части фолда внутри CV.

**Алгоритм Генерации Одного Синтетического Примера:**

**Шаг 1: Выбор Базового Объекта**
Выбрать случайный объект $x_i$ из **минорного** класса.

**Шаг 2: Поиск Соседей**
Найти $k$ ближайших соседей объекта $x_i$ **среди объектов минорного же класса**.

**Шаг 3: Выбор Соседа для Интерполяции**
Случайно выбрать одного из этих $k$ соседей, обозначим его $x_{zi}$.

**Шаг 4: Генерация Синтетического Объекта**
Вычислить новый вектор признаков $x_{new}$ как линейную интерполяцию между $x_i$ и $x_{zi}$:
$$
\boxed{
x_{new} = x_i + \lambda \cdot (x_{zi} - x_i)
}
$$
Где:

* $x_i$ - вектор признаков базового объекта.
* $x_{zi}$ - вектор признаков выбранного соседа.
* $\lambda$ - случайное число, выбранное равномерно из диапазона **[0, 1]**.
* Операции сложения и умножения векторов выполняются поэлементно.

**Шаг 5: Повторение**
Повторять шаги 1-4 до тех пор, пока не будет сгенерировано желаемое количество синтетических примеров минорного класса.

* **Объяснение:** SMOTE создает новые точки на линиях, соединяющих существующие минорные точки с их ближайшими минорными соседями. Это позволяет увеличить представленность минорного класса, не просто дублируя существующие точки.

## 4. Взвешивание Классов (Class Weighting)

**Цель:** Модифицировать функцию потерь, чтобы ошибки на объектах редкого (минорного) класса наказывались сильнее, заставляя модель уделять им больше внимания.

**Пример: Модификация Log Loss для Бинарной Классификации**

**Исходная Log Loss:**
$$
J(w) = -\frac{1}{m} \sum_{i=1}^{m} [ y^{(i)} \log(\hat{p}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{p}^{(i)}) ]
$$

**Взвешенная Log Loss:**
Добавляются веса $w_0$ (для класса 0) и $w_1$ (для класса 1), которые обратно пропорциональны частотам классов.
$$
\boxed{
J_{weighted}(w) = -\frac{1}{m} \sum_{i=1}^{m} w_{y^{(i)}} [ y^{(i)} \log(\hat{p}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{p}^{(i)}) ]
}
$$
Где $w_{y^{(i)}}$ - вес, соответствующий истинному классу $y^{(i)}$ объекта $i$.

* Если $y^{(i)} = 1$, используется вес $w_1$.
* Если $y^{(i)} = 0$, используется вес $w_0$.

**Расчет Весов (например, `class_weight='balanced'` в sklearn):**
Веса обычно рассчитываются обратно пропорционально частоте класса:
$$
\boxed{
w_k = \frac{m}{K \cdot m_k}
}
$$
Где:

* $w_k$ - вес для класса $k$.
* $m$ - общее число объектов.
* $K$ - общее число классов (здесь $K=2$).
* $m_k$ - число объектов класса $k$.

* **Объяснение:** Если класс $k$ редкий ($m_k$ мало), его вес $w_k$ будет большим. Ошибки на объектах этого класса будут умножаться на больший вес в функции потерь, что заставит алгоритм оптимизации (GD) сильнее стараться их исправить.

## 5. Статистическая Значимость (Концептуальные Формулы)

**Цель:** Формально определить, является ли наблюдаемая разница в метриках между моделями A и B случайной или систематической.

**5.1 Доверительный Интервал (CI) для Разности Средних (Пример)**
При сравнении средних метрик $\bar{M}_A$ и $\bar{M}_B$, полученных по фолдам CV, можно построить CI для разности $\Delta = \bar{M}_A - \bar{M}_B$.

**Общая структура CI (для уровня доверия $1-\alpha$):**
$$
\boxed{
CI(\Delta) = \bar{\Delta} \pm t_{crit} \cdot SE(\bar{\Delta})
}
$$
Где:

* $\bar{\Delta} = \bar{M}_A - \bar{M}_B$ - наблюдаемая средняя разность.
* $SE(\bar{\Delta})$ - **стандартная ошибка** оценки средней разности (зависит от стандартных отклонений и числа фолдов, для парных данных считается по разностям $M_{A,k} - M_{B,k}$).
* $t_{crit}$ - критическое значение t-распределения (или z-распределения для больших выборок) для уровня $\alpha$ и степеней свободы.

* **Интерпретация:** Если CI **не содержит 0**, то разница статистически значима на уровне $\alpha$.

**5.2 P-value из Статистического Теста (Концепция)**
Применяется статистический тест (например, парный t-тест) к разностям метрик $d_k = M_{A,k} - M_{B,k}$.

**Нулевая гипотеза $H_0$:** Средняя разность равна нулю ($\mu_d = 0$).
**Альтернативная гипотеза $H_1$:** Средняя разность не равна нулю ($\mu_d \ne 0$).

**Результат теста:** P-value.
$$
\boxed{
\text{P-value} = P(\text{наблюдать данные как у нас или более экстремальные} | H_0 \text{ верна})
}
$$

* **Интерпретация:** Если **P-value < $\alpha$** (заданный уровень значимости, обычно 0.05), то **отвергаем $H_0$**. Разница статистически значима.

*(Примечание: Детальный вывод формул стандартной ошибки и тестовых статистик выходит за рамки базового обзора валидации, но важно понимать концепцию CI и p-value).*
