# Детальный Вывод Формул и Концепций: Статистическая Значимость

*(Используем обозначения: $m$ - число объектов, $n$ - число признаков, $K$ - число фолдов в CV, $N$ - размер тестовой выборки, $M_A, M_B$ - значения метрики для моделей A и B, $\bar{M}$ - среднее значение метрики, $s_M$ - стандартное отклонение метрики, $d_k = M_{A,k} - M_{B,k}$ - разность метрик на $k$-ом фолде, $\bar{d}$ - средняя разность, $s_d$ - стандартное отклонение разностей, $\alpha$ - уровень значимости, $\mu_M, \mu_d$ - истинные средние значения, CI - доверительный интервал, SE - стандартная ошибка, $R$ - число бутстрап-итераций).*

## 1. Оценка Метрики и ее Вариативность

* **Проблема:** Метрика $M$, посчитанная на конечной выборке (тестовый сет или фолд CV) размера $N$, является **оценкой** истинного значения $\mu_M$. Эта оценка имеет **дисперсию (variance)** из-за случайности выборки.
* **Стандартная Ошибка Среднего (Standard Error of the Mean - SE):** Если у нас есть несколько оценок метрики (например, $M_1, ..., M_K$ по фолдам CV), мы можем оценить стандартное отклонение *среднего значения* $\bar{M}$. Это и есть стандартная ошибка.
    $$
    SE_{\bar{M}} = \frac{s_M}{\sqrt{K}}
    $$
  * $s_M$: Выборочное стандартное отклонение значений метрики $M_1, ..., M_K$.
        $$
        s_M = \sqrt{\frac{1}{K-1} \sum_{k=1}^{K} (M_k - \bar{M})^2}
        $$
  * $K$: Количество фолдов (или независимых оценок).
  * **Объяснение:** SE показывает, насколько в среднем наше выборочное среднее $\bar{M}$ отклоняется от истинного среднего $\mu_M$. Чем больше $K$, тем меньше SE, тем надежнее наша оценка $\bar{M}$.

## 2. Доверительный Интервал (Confidence Interval - CI) для Средней Метрики

* **Цель:** Оценить диапазон, в котором с заданной уверенностью (обычно 95%) лежит истинное среднее значение метрики $\mu_M$.
* **Формула (на основе результатов CV):**
    $$
    \text{CI for } \mu_M = \bar{M} \pm \text{Погрешность}
    $$
    $$
    \text{Погрешность} = t_{\alpha/2, K-1} \cdot SE_{\bar{M}} = t_{\alpha/2, K-1} \cdot \frac{s_M}{\sqrt{K}}
    $$
  * $\bar{M}$: Среднее значение метрики по $K$ фолдам.
  * $s_M$: Стандартное отклонение метрики по $K$ фолдам.
  * $K$: Количество фолдов.
  * $t_{\alpha/2, K-1}$: **Критическое значение (квантиль)** t-распределения Стьюдента с $K-1$ степенями свободы для уровня доверия $1-\alpha$.
    * Для 95% CI, $\alpha = 0.05$, и мы ищем $t_{0.025, K-1}$.
    * При большом $K$ (например, $K \ge 30$), t-распределение близко к нормальному, и можно использовать z-квантиль $z_{\alpha/2} \approx 1.96$ для 95% CI.
  * **Объяснение:** Мы берем нашу точечную оценку $\bar{M}$ и добавляем/вычитаем "запас" (погрешность), который зависит от разброса оценок ($s_M$), количества оценок ($K$) и нашего желаемого уровня уверенности (через $t$-квантиль). Чем больше разброс или меньше фолдов, тем шире будет интервал.

## 3. Сравнение Моделей A и B с Помощью CV: Парный t-тест

* **Цель:** Проверить гипотезу о том, что средние значения метрик моделей A и B равны, используя результаты CV.
* **Данные:** Пары метрик $(M_{A,1}, M_{B,1}), ..., (M_{A,K}, M_{B,K})$. Рассчитываем разности $d_k = M_{A,k} - M_{B,k}$.
* **Гипотезы:**
  * $H_0: \mu_d = 0$ (Средняя разность метрик равна нулю, т.е. модели не различаются).
  * $H_1: \mu_d \ne 0$ (Средняя разность не равна нулю, т.е. модели различаются).
* **Предположение:** Разности $d_k$ распределены примерно нормально (или $K$ велико).
* **Статистика Теста (t-статистика):**
    $$
    t = \frac{\bar{d} - 0}{SE_{\bar{d}}} = \frac{\bar{d}}{s_d / \sqrt{K}}
    $$
  * $\bar{d}$: Среднее значение попарных разностей $d_1, ..., d_K$.
        $$
        \bar{d} = \frac{1}{K} \sum_{k=1}^{K} d_k = \frac{1}{K} \sum_{k=1}^{K} (M_{A,k} - M_{B,k})
        $$
  * $s_d$: Стандартное отклонение попарных разностей $d_1, ..., d_K$.
        $$
        s_d = \sqrt{\frac{1}{K-1} \sum_{k=1}^{K} (d_k - \bar{d})^2}
        $$
  * $SE_{\bar{d}} = s_d / \sqrt{K}$: Стандартная ошибка средней разности.
  * **Объяснение:** Статистика $t$ измеряет, на сколько стандартных ошибок средняя наблюдаемая разность $\bar{d}$ отклоняется от нуля (значения, предполагаемого $H_0$). Чем дальше $t$ от нуля, тем меньше вероятность получить такую разность случайно, если $H_0$ верна.
* **Принятие Решения (через p-value):**
    1. По вычисленному значению $t$ и числу степеней свободы $df = K-1$ находится **p-value**.
        * **P-value:** Вероятность получить значение t-статистики, такое же или более экстремальное, чем наблюдаемое, *если нулевая гипотеза $H_0$ верна*.
    2. Сравнить p-value с уровнем значимости $\alpha$ (обычно 0.05).
        * Если **p-value < $\alpha$**: Отвергаем $H_0$. Разница между моделями **статистически значима**.
        * Если **p-value $\ge \alpha$**: Не отвергаем $H_0$. Недостаточно оснований считать разницу значимой.
* **Принятие Решения (через Доверительный Интервал для $\mu_d$):**
    1. Строится CI для средней разности $\mu_d$:
        $$
        \text{CI for } \mu_d = \bar{d} \pm t_{\alpha/2, K-1} \cdot \frac{s_d}{\sqrt{K}}
        $$
    2. Проверяется, содержит ли CI ноль.
        * Если CI **не содержит 0**: Отвергаем $H_0$. Разница статистически значима.
        * Если CI **содержит 0**: Не отвергаем $H_0$.

## 4. Сравнение Моделей A и B на Одном Тестовом Сете: Бутстрап (Bootstrap)

* **Цель:** Оценить стат. значимость разницы метрик $\Delta = M_A - M_B$, имея только один тестовый сет $D_{test}$.
* **Идея:** Генерируем множество "псевдо" тестовых сетов $D_{boot}$ путем выборки с возвращением из $D_{test}$. Смотрим на распределение разницы метрик $\Delta_{boot}$ на этих псевдо-сетах.
* **Алгоритм (Концептуально, без формул вывода):**
    1. Повторить $R$ раз (например, $R=1000$):
        * Сгенерировать $D_{boot}$ (выборка $N$ раз с возвращением из $D_{test}$).
        * Посчитать $M_{A, boot}$ и $M_{B, boot}$ на $D_{boot}$.
        * Записать разницу $\Delta_{boot} = M_{A, boot} - M_{B, boot}$.
    2. Получить распределение из $R$ значений $\Delta_{boot}$.
* **Оценка Значимости (через Перцентильный CI):**
    1. Отсортировать $\Delta_{boot, 1}, ..., \Delta_{boot, R}$.
    2. Найти перцентили. Например, для 95% CI:
        * Нижняя граница $\Delta_{low} = (\alpha/2)$-перцентиль (т.е. 2.5-й перцентиль).
        * Верхняя граница $\Delta_{high} = (1 - \alpha/2)$-перцентиль (т.е. 97.5-й перцентиль).
    3. 95% CI для разницы метрик: $[\Delta_{low}, \Delta_{high}]$.
    4. **Решение:** Если интервал **не содержит нуля**, то наблюдаемая разница $\Delta$ считается **статистически значимой**.
* **Оценка Значимости (через p-value - приближенно):**
    1. Если исходная разница $\Delta = M_A - M_B > 0$, то $p_{one-sided} = \frac{\text{count}(\Delta_{boot} \le 0)}{R}$.
    2. Если $\Delta < 0$, то $p_{one-sided} = \frac{\text{count}(\Delta_{boot} \ge 0)}{R}$.
    3. Для двустороннего теста: $p_{value} \approx 2 \cdot p_{one-sided}$.
    4. **Решение:** Если p-value < $\alpha$, отвергаем $H_0$.

## 5. Ключевые Статистические Термины (Резюме)

* **$H_0$ (Нулевая гипотеза):** Нет разницы / нет эффекта.
* **$H_1$ (Альтернативная гипотеза):** Есть разница / есть эффект.
* **$\alpha$ (Уровень значимости):** Порог для p-value (обычно 0.05). Вероятность ошибки I рода.
* **P-value:** Вероятность наблюдать текущие (или более экстремальные) данные, *если $H_0$ верна*. (Маленькое p-value $\implies$ отвергаем $H_0$).
* **CI (Доверительный интервал):** Диапазон, который с заданной уверенностью содержит истинное значение параметра. (Если CI для разности не содержит 0 $\implies$ отвергаем $H_0$).
* **SE (Стандартная ошибка):** Мера неопределенности / разброса *оценки* параметра (например, среднего).
