% >>> Реструктурированный Контент: Фундамент ML - Основные Концепции v2

% ================================================
% Введение в Машинное Обучение
% ================================================
\begin{textbox}{Определение Машинного Обучения (ML)}
    \textbf{Машинное обучение} — это область искусственного интеллекта, изучающая методы построения алгоритмов, способных обучаться на основе данных. Вместо явного программирования правил, ML-модели самостоятельно выявляют закономерности в предоставленных данных и используют их для решения поставленных задач (например, классификации, регрессии, кластеризации).
\end{textbox}

% ================================================
% Секция I: Типы Машинного Обучения
% ================================================
\section{Типы Машинного Обучения}

% --- I.A: Обучение с Учителем (Supervised Learning) ---
\subsection{A Обучение с Учителем (Supervised Learning)}
\begin{myblock}{Обучение на размеченных данных}
    \textbf{Задача:} Модель обучается на наборе данных, где для каждого объекта (\textit{примера}) заданы входные \textbf{признаки (features)} и соответствующий правильный выход (\textbf{метка класса} или \textbf{целевое значение}, label/target).
    \textbf{Цель:} Построить модель, способную предсказывать метку/значение для новых, ранее не виданных объектов по их признакам.
\end{myblock}

\begin{myexampleblock}{Подтипы Supervised Learning}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Классификация (Classification):} Предсказание категориальной метки. Выход модели принадлежит к дискретному множеству классов.
            \textit{Примеры:} Определение спама в письмах (спам/не спам), распознавание изображений (кошка/собака/птица), кредитный скоринг (одобрить/отклонить).
        \item \textbf{Регрессия (Regression):} Предсказание непрерывного числового значения.
            \textit{Примеры:} Прогнозирование цены недвижимости, оценка температуры воздуха, предсказание спроса на товар.
    \end{itemize}
\end{myexampleblock}

% --- I.B: Обучение без Учителя (Unsupervised Learning) ---
\subsection{B Обучение без Учителя (Unsupervised Learning)}
\begin{myblock}{Поиск структуры в неразмеченных данных}
    \textbf{Задача:} Модель обучается на данных без каких-либо меток или целевых значений. Алгоритм должен самостоятельно найти внутренние закономерности, структуру или взаимосвязи в данных.
\end{myblock}

\begin{myexampleblock}{Задачи Unsupervised Learning}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Кластеризация (Clustering):} Разделение набора данных на группы (кластеры) схожих между собой объектов. Объекты внутри одного кластера должны быть более похожи друг на друга, чем на объекты из других кластеров.
            \textit{Примеры:} Сегментация клиентов по покупательскому поведению, группировка новостных статей по темам.
        \item \textbf{Снижение размерности (Dimensionality Reduction):} Уменьшение количества признаков в данных при сохранении максимально возможного объема полезной информации. Используется для визуализации, сжатия данных или подготовки данных для других ML-алгоритмов.
            \textit{Примеры:} Метод главных компонент (PCA), t-распределенное стохастическое вложение соседей (t-SNE).
        \item \textbf{Поиск аномалий (Anomaly Detection):} Выявление объектов, которые значительно отличаются от основной массы данных.
            \textit{Примеры:} Обнаружение мошеннических транзакций, выявление дефектных изделий.
    \end{itemize}
\end{myexampleblock}

% --- I.C: Обучение с Подкреплением (Reinforcement Learning) ---
\subsection{C Обучение с Подкреплением (Reinforcement Learning, RL)}
\begin{myblock}{Обучение через взаимодействие со средой}
    \textbf{Задача:} \textbf{Агент} (модель) учится принимать последовательность \textbf{действий} в некоторой \textbf{среде} с целью максимизации кумулятивной \textbf{награды} (reward), получаемой от среды в ответ на действия. Обучение происходит методом проб и ошибок.
    \textit{Примеры:} Обучение игровых ботов (шахматы, Go, видеоигры), управление роботами, оптимизация торговых стратегий, персонализированные рекомендации.
\end{myblock}

% ================================================
% Секция II: Процесс Разработки и Разделение Данных
% ================================================
\section{II. Процесс Разработки и Разделение Данных}

% --- II.A: Основные Этапы ML-проекта ---
\subsection{A Основные Этапы ML-проекта}
\begin{textbox}{Типичный жизненный цикл ML-модели}
    Процесс создания ML-решения обычно включает следующие шаги (могут итерироваться):
    \begin{enumerate}[nosep]
        \item \textbf{Определение проблемы и цели:} Четкая постановка бизнес-задачи и метрик успеха.
        \item \textbf{Сбор данных:} Получение релевантных данных для обучения.
        \item \textbf{Анализ и предварительная обработка данных (EDA \& Preprocessing):} Очистка, исследование, обработка пропусков, кодирование категорий, создание новых признаков (Feature Engineering). \textit{(Часто наиболее трудоемкий этап)}.
        \item \textbf{Выбор модели(ей):} Подбор подходящих алгоритмов для задачи.
        \item \textbf{Обучение модели:} Подбор параметров модели на обучающей выборке.
        \item \textbf{Настройка гиперпараметров и выбор лучшей модели:} Использование валидационной выборки.
        \item \textbf{Оценка качества:} Финальная оценка на тестовой выборке.
        \item \textbf{Развертывание (Deployment):} Внедрение модели в рабочую среду.
        \item \textbf{Мониторинг и поддержка:} Отслеживание производительности модели и ее переобучение при необходимости.
    \end{enumerate}
\end{textbox}

% --- II.B: Разделение Данных: Train / Validation / Test ---
\subsection{B Разделение Данных: Train / Validation / Test}
\begin{myexampleblock}{Цель разделения данных}
    Ключевая задача ML — построить модель, способную хорошо \textbf{обобщать} (generalize), то есть давать точные предсказания на новых, ранее не виданных данных. Чтобы объективно оценить эту способность, исходный набор данных разделяют:

    \begin{enumerate}[label=\arabic*., wide, labelindent=0pt, itemsep=1ex]
        \item \textbf{Обучающая выборка (Train Set):} \newline
        Используется непосредственно для \textit{обучения} модели — поиска оптимальных значений её внутренних \textbf{параметров} (например, весов в линейной модели или нейросети). Модель "видит" эти данные и подстраивается под них.
        \textit{Назначение: Найти закономерности в данных.}

        \item \textbf{Валидационная выборка (Validation Set):} \newline
        Используется для \textit{настройки} \textbf{гиперпараметров} модели (параметров, которые не обучаются напрямую, а задаются до начала обучения, например, степень полинома, learning rate, параметр регуляризации $\lambda$) и для \textit{выбора} наилучшей модели из нескольких кандидатов. Модель не обучается на этих данных, но её производительность на них используется для принятия решений о её структуре или настройках.
        \textit{Назначение: Подобрать оптимальную конфигурацию модели.}

        \item \textbf{Тестовая выборка (Test Set):} \newline
        Используется \textit{только один раз} в самом конце для получения \textit{финальной, объективной оценки} качества лучшей выбранной и настроенной модели. Эти данные модель не должна была "видеть" ни на этапе обучения, ни на этапе настройки гиперпараметров. Результат на тестовой выборке имитирует производительность модели на реальных новых данных.
        \textit{Назначение: Оценить финальную производительность выбранной модели.}
    \end{enumerate}

    \begin{alerttextbox}{Важное правило}
        Категорически нельзя использовать тестовую выборку для подбора гиперпараметров или выбора модели. Это приведет к "утечке" информации из теста в процесс настройки и, как следствие, к нереалистично завышенной оценке качества модели.
    \end{alerttextbox}
\end{myexampleblock}

% ================================================
% Секция III: Переобучение и Недообучение
% ================================================
\section{Переобучение и Недообучение}

% --- III.A: Фундаментальные Проблемы Обучения ---
\subsection{III.A Фундаментальные Проблемы Обучения}
\begin{alerttextbox}{Риски при построении модели}
    При обучении модели существует две основные нежелательные ситуации, связанные с её сложностью и способностью к обобщению:
\end{alerttextbox}

\begin{myblock}{Недообучение (Underfitting)}
    \textbf{Описание:} Модель слишком проста для улавливания сложных закономерностей в данных. Она не способна хорошо описать даже обучающую выборку.
    \textbf{Характеристики:}
    \begin{itemize}[nosep, leftmargin=*]
        \item Плохое качество (высокая ошибка) как на обучающей (\texttt{Train}), так и на валидационной/тестовой (\texttt{Valid}/\texttt{Test}) выборках.
        \item Модель обладает высоким \textbf{смещением (Bias)}.
    \end{itemize}
    \textbf{Причины:} Недостаточная сложность модели (e.g., линейная модель для нелинейных данных), нерелевантные признаки.
\end{myblock}

\begin{myblock}{Переобучение (Overfitting)}
    \textbf{Описание:} Модель излишне сложна и "запоминает" обучающие данные, включая случайный шум и выбросы, вместо того чтобы улавливать общие закономерности.
    \textbf{Характеристики:}
    \begin{itemize}[nosep, leftmargin=*]
        \item Отличное качество (низкая ошибка) на обучающей выборке (\texttt{Train}).
        \item Значительно худшее качество (высокая ошибка) на валидационной/тестовой выборке (\texttt{Valid}/\texttt{Test}).
        \item Модель обладает высоким \textbf{разбросом (Variance)}.
    \end{itemize}
    \textbf{Причины:} Слишком сложная модель (e.g., глубокое дерево решений без ограничений, многослойная нейросеть), мало данных, "шумные" данные.
\end{myblock}

\begin{textbox}{Цель}
    Найти "золотую середину" — модель, которая достаточно сложна, чтобы уловить основные зависимости в данных, но при этом устойчива к шуму и хорошо обобщается на новые данные.
\end{textbox}

% ================================================
% Секция IV: Дилемма Смещения-Разброса (Bias-Variance Tradeoff)
% ================================================
\section{Дилемма Смещения-Разброса (Bias-Variance Tradeoff)}

% --- IV.A: Компоненты Ошибки Модели ---
\subsection{A Компоненты Ошибки Модели}
\begin{textbox}{Разложение ожидаемой ошибки}
    Ожидаемую ошибку предсказания модели на новых данных (Expected Prediction Error) можно теоретически разложить на три составляющие:
    \[ \mathbb{E}[\text{Error}] = \underbrace{\text{Bias}^2}_{\text{Смещение}} + \underbrace{\text{Variance}}_{\text{Разброс}} + \underbrace{\sigma^2}_{\text{Неустранимая ошибка}} \]
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Смещение (Bias):} Ошибка, возникающая из-за неверных предположений, заложенных в модель. Отражает, насколько \textit{в среднем} предсказания модели отклоняются от истинного значения. Высокое смещение (\textbf{High Bias}) характерно для простых моделей, неспособных уловить сложную структуру данных (приводит к \textbf{недообучению}).
        \item \textbf{Разброс (Variance):} Ошибка, возникающая из-за чувствительности модели к малым изменениям в обучающей выборке. Отражает, насколько сильно будут различаться модели, обученные на разных подвыборках данных. Высокий разброс (\textbf{High Variance}) характерен для сложных моделей, которые подстраиваются под шум (приводит к \textbf{переобучению}).
        \item \textbf{Неустранимая ошибка (Irreducible Error, $\sigma^2$):} Минимальный уровень ошибки, присущий самим данным из-за случайного шума или скрытых факторов, который не может быть уменьшен выбором другой модели.
    \end{itemize}
\end{textbox}

% --- IV.B: Суть Дилеммы ---
\subsection{B Суть Дилеммы}
\begin{myblock}{Компромисс между Bias и Variance}
    Существует обратная зависимость между смещением и разбросом при изменении сложности модели:
    \begin{itemize}[nosep, leftmargin=*]
        \item Увеличение сложности модели (e.g., добавление признаков, увеличение глубины дерева) обычно \textit{уменьшает смещение}, но \textit{увеличивает разброс}.
        \item Уменьшение сложности модели (e.g., упрощение, добавление регуляризации) обычно \textit{уменьшает разброс}, но \textit{увеличивает смещение}.
    \end{itemize}
    \textbf{Задача:} Найти оптимальную сложность модели, которая минимизирует \textit{суммарную ошибку} ($\text{Bias}^2 + \text{Variance}$) на новых данных. Этот оптимум обычно достигается при некотором компромиссном уровне смещения и разброса.

    \textbf{Примеры моделей:}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textit{Низкая сложность (Low Variance, High Bias):} Линейная регрессия, Логистическая регрессия.
        \item \textit{Высокая сложность (High Variance, Low Bias):} Неограниченные Деревья решений, K-ближайших соседей (с малым k), Нейронные сети без регуляризации.
        \item \textit{Баланс (часто):} Деревья с ограничениями, Ансамбли (Random Forest, Gradient Boosting), Регуляризованные модели (Ridge, Lasso), Нейросети с регуляризацией.
    \end{itemize}
\end{myblock}

% ================================================
% Секция V: Диагностика Моделей
% ================================================
\section{Диагностика Моделей}

% --- V.A: Кривые Обучения (Learning Curves) ---
\subsection{A Кривые Обучения (Learning Curves)}
\begin{myexampleblock}{Визуальная диагностика Bias и Variance}
    \textbf{Кривые обучения} — это графики, отображающие метрику качества модели (например, ошибку MSE, Accuracy, F1-score) в зависимости от объема обучающих данных или итерации/эпохи обучения. Обычно строятся две кривые: одна для \textbf{обучающей выборки (Train)}, другая для \textbf{валидационной выборки (Validation)}. Анализ их поведения помогает диагностировать проблемы недообучения и переобучения.

    \textbf{Типичные сценарии анализа кривых:}

    \begin{enumerate}[label=\arabic*., wide, labelindent=0pt, itemsep=1ex]
        \item \textbf{Признаки Недообучения (High Bias):}
            \begin{itemize}[nosep, leftmargin=*, itemsep=0.5ex]
                \item Кривая ошибки на \texttt{Train} и \texttt{Valid} стабилизируются на \textit{высоком} уровне.
                \item Разрыв (gap) между кривыми \texttt{Train} и \texttt{Valid} \textit{небольшой}.
                \item Качество модели неудовлетворительное, добавление новых данных в обучение почти не улучшает ситуацию.
            \end{itemize}
            \textbf{Возможные действия:}
            \begin{itemize}[label=\textbullet, nosep, leftmargin=*]
                 \item Использовать более сложную модель (e.g., полиномиальные признаки, больше слоев/нейронов).
                 \item Добавить новые, более информативные признаки (Feature Engineering).
                 \item Уменьшить силу регуляризации (если используется).
            \end{itemize}

        \item \textbf{Признаки Переобучения (High Variance):}
            \begin{itemize}[nosep, leftmargin=*, itemsep=0.5ex]
                \item Кривая ошибки на \texttt{Train} находится на \textit{низком} уровне (модель хорошо подогналась под обучение).
                \item Кривая ошибки на \texttt{Valid} находится на \textit{значительно более высоком} уровне.
                \item Существует \textit{большой разрыв} (gap) между кривыми \texttt{Train} и \texttt{Valid}.
                \item Увеличение объема обучающих данных может помочь сблизить кривые и улучшить качество на валидации.
            \end{itemize}
            \textbf{Возможные действия:}
            \begin{itemize}[label=\textbullet, nosep, leftmargin=*]
                 \item Собрать больше обучающих данных.
                 \item Использовать регуляризацию (L1, L2, Dropout, etc.).
                 \item Упростить модель (e.g., уменьшить глубину дерева, количество признаков через Feature Selection).
                 \item Использовать методы ансамблирования (особенно Bagging).
            \end{itemize}

        \item \textbf{Желаемый сценарий ("Хороший баланс"):}
            \begin{itemize}[nosep, leftmargin=*, itemsep=0.5ex]
                \item Кривые \texttt{Train} и \texttt{Valid} сходятся к \textit{низкому} уровню ошибки.
                \item Разрыв между кривыми \textit{небольшой и стабильный}.
            \end{itemize}
             \textit{Это указывает на то, что модель адекватно уловила закономерности и хорошо обобщается.}
    \end{enumerate}
\end{myexampleblock}