% >>> Контент для шпаргалки: Фундамент ML - Основные Концепции

% --- Введение ---
\begin{textbox}{Что такое Машинное Обучение?}
    \textbf{Машинное обучение (Machine Learning, ML)} — это раздел искусственного интеллекта, который позволяет компьютерам "обучаться" на данных без явного программирования. Модель сама находит закономерности в данных и использует их для решения задач.
    
    \textit{Аналогия: Представь, что ты учишься отличать яблоки и груши. Вместо того чтобы тебе дали четкие инструкции ("если зеленое и круглое - яблоко"), тебе показывают много примеров яблок и груш. Ты сам вырабатываешь правила.}
    \end{textbox}
    
    % --- Раздел 1 ---
    \section{Типы Машинного Обучения}
    
    \begin{myblock}{Основные парадигмы ML}
    В зависимости от задачи и типа данных, выделяют несколько основных типов ML:
    
    \begin{itemize}
        \item \textbf{Обучение с учителем (Supervised Learning):}
            \begin{itemize}
                \item \textbf{Задача:} Модель учится на размеченных данных, где для каждого входа (\textbf{признаки}, features) известен правильный выход (\textbf{метка}, label или target).
                \item \textbf{Цель:} Предсказать метку для новых, невиданных ранее входных данных.
                \item \textbf{Примеры:}
                    \begin{itemize}
                        \item \textbf{Классификация (Classification):} Предсказание категориальной метки (e.g., спам/не спам, кошка/собака).
                        \item \textbf{Регрессия (Regression):} Предсказание непрерывного значения (e.g., цена дома, температура воздуха).
                    \end{itemize}
            \end{itemize}
        \item \textbf{Обучение без учителя (Unsupervised Learning):}
            \begin{itemize}
                \item \textbf{Задача:} Модель учится на неразмеченных данных, пытаясь найти скрытую структуру или закономерности. Правильных ответов нет.
                \item \textbf{Примеры:}
                    \begin{itemize}
                        \item \textbf{Кластеризация (Clustering):} Группировка похожих объектов (e.g., сегментация клиентов).
                        \item \textbf{Снижение размерности (Dimensionality Reduction):} Уменьшение количества признаков с сохранением важной информации (e.g., PCA, t-SNE для визуализации).
                    \end{itemize}
            \end{itemize}
        \item \textbf{Обучение с подкреплением (Reinforcement Learning):}
            \begin{itemize}
                \item \textbf{Задача:} Агент учится взаимодействовать со средой, совершая действия и получая награды или штрафы, с целью максимизировать итоговую награду.
                \item \textbf{Примеры:} Обучение игровых ботов, робототехника, системы рекомендаций.
            \end{itemize}
    \end{itemize}
    На собеседованиях чаще всего спрашивают про \textbf{Supervised Learning}.
    \end{myblock}
    
    % --- Раздел 2 ---
    \section{Процесс Разработки и Разделение Данных}
    
    \begin{textbox}{Этапы ML проекта (очень упрощенно)}
    \begin{enumerate}
        \item Постановка задачи.
        \item Сбор и подготовка данных (\textit{часто самый трудоемкий этап!}).
        \item Выбор и обучение модели.
        \item Оценка качества модели.
        \item Развертывание и мониторинг.
    \end{enumerate}
    \end{textbox}
    
    \begin{myexampleblock}{Зачем делить данные? Train / Validation / Test}
    Чтобы честно оценить способность модели \textbf{обобщать} (generalize) на новых данных, исходный набор данных делят на три части:
    
    \begin{itemize}
        \item \textbf{Обучающая выборка (Train Set):} Используется непосредственно для обучения модели — подбора её внутренних параметров (весов). \textit{Аналогия: Домашние задания, на которых студент учится.}
        \item \textbf{Валидационная выборка (Validation Set):} Используется для настройки \textbf{гиперпараметров} модели (e.g., скорость обучения, глубина дерева, параметр регуляризации) и/или \textbf{выбора наилучшего алгоритма} из нескольких кандидатов. Модель не обучается на этих данных напрямую, но мы используем её результаты для принятия решений о структуре/настройках модели. \textit{Аналогия: Пробные экзамены, по результатам которых студент корректирует свою подготовку или выбирает стратегию.}
        \item \textbf{Тестовая выборка (Test Set):} Используется \textbf{только один раз} в самом конце для финальной, непредвзятой оценки качества лучшей выбранной и настроенной модели. Эти данные модель никогда не "видела" ни при обучении, ни при настройке. \textit{Аналогия: Финальный экзамен, который показывает реальные знания студента.}
    \end{itemize}
    
    \textbf{Важно:} Никогда не используйте тестовую выборку для настройки модели! Это приведет к завышенной (нереалистичной) оценке качества.
    \end{myexampleblock}
    
    % --- Раздел 3 ---
    \section{Переобучение и Недообучение}
    
    \begin{alerttextbox}{Ключевая проблема: Баланс Модели}
    При обучении модели мы всегда сталкиваемся с риском двух крайностей:
    
    \begin{itemize}
        \item \textbf{Недообучение (Underfitting):} Модель слишком простая, она не может уловить основные закономерности в данных. Плохо работает как на обучающих, так и на новых данных. Характеризуется высоким \textbf{смещением (Bias)}. \textit{Аналогия: Студент, который почти не готовился и плохо сдает даже тесты по пройденному материалу.}
        \item \textbf{Переобучение (Overfitting):} Модель слишком сложная, она "вызубрила" обучающие данные, включая случайный шум. Отлично работает на обучающих данных, но плохо обобщает на новые, невиданные данные. Характеризуется высоким \textbf{разбросом (Variance)}. \textit{Аналогия: Студент, который вызубрил ответы на конкретные билеты, но не понял суть и "плывет" на похожих вопросах.}
    \end{itemize}
    \textbf{Цель:} Построить модель, которая находит золотую середину — хорошо улавливает общие закономерности, но игнорирует шум, и хорошо работает на новых данных.
    \end{alerttextbox}
    
    % --- Раздел 4 ---
    \section{Дилемма Смещения-Разброса (Bias-Variance Tradeoff)}
    
    \begin{textbox}{Анатомия Ошибки Модели}
    Общая ожидаемая ошибка модели на новых данных может быть разложена на три компонента:
    \[ \text{Total Error} = \text{Bias}^2 + \text{Variance} + \text{Irreducible Error} \]
    \begin{itemize}
        \item \textbf{Смещение (Bias):} Систематическая ошибка модели. Насколько предсказания \textit{в среднем} отклоняются от истинных значений. Высокое смещение ($\text{High Bias}$) означает, что модель слишком простая и не улавливает зависимости (Недообучение). (\textit{Модель систематически ошибается / не попадает в цель}). \textit{Аналогия: Стрелок, который всегда целится левее центра мишени. Пули ложатся кучно, но не туда.}
        \item \textbf{Разброс (Variance):} Чувствительность модели к изменениям в обучающей выборке. Насколько сильно будут различаться модели, обученные на разных подмножествах данных. Высокий разброс ($\text{High Variance}$) означает, что модель слишком сложная и подстраивается под шум (Переобучение). (\textit{Модель нестабильна / сильно реагирует на данные}). \textit{Аналогия: Стрелок, у которого сильно дрожат руки. Он целится в центр, но пули ложатся с большим разбросом вокруг него.}
        \item \textbf{Неустранимая ошибка (Irreducible Error):} Минимально возможная ошибка, обусловленная шумом в самих данных, который не может быть устранен никакой моделью.
    \end{itemize}
    \end{textbox}
    
    \begin{myblock}{Дилемма (Tradeoff)}
    Часто попытка уменьшить смещение (усложняя модель) приводит к увеличению разброса, и наоборот, попытка уменьшить разброс (упрощая модель, добавляя регуляризацию) может увеличить смещение.
    
    \textbf{Задача Data Scientist'а} — найти модель с такой сложностью, которая обеспечивает наилучший компромисс между смещением и разбросом, минимизируя \textit{общую ошибку} на \textbf{новых} данных (обычно оценивается на валидационной выборке).
    
    \begin{itemize}
        \item \textbf{Простые модели} (e.g., Линейная регрессия): Low Variance, High Bias.
        \item \textbf{Сложные модели} (e.g., Глубокие деревья решений, нейросети без регуляризации): High Variance, Low Bias.
    \end{itemize}
    \end{myblock}
    
    % --- Раздел 5 ---
    \section{Диагностика: Кривые Обучения}
    
    \begin{myexampleblock}{Анализ Кривых Обучения}
    \textbf{Кривые обучения} — это графики, показывающие метрику качества (например, ошибку MSE или долю правильных ответов Accuracy) на \textbf{обучающей} (\texttt{Train}) и \textbf{валидационной} (\texttt{Valid}) выборках в зависимости от некоторого параметра (чаще всего — размера обучающей выборки или номера эпохи обучения).
    
    \textbf{Анализ кривых:}
    \begin{itemize}
        \item \textbf{Признак Недообучения (High Bias):}
            \begin{itemize}
                \item Ошибка на \texttt{Train} и \texttt{Valid} высокая.
                \item Кривые быстро сходятся и выходят на плато.
                \item Разрыв между кривыми маленький.
                \item \textit{Что делать?} Усложнять модель (больше слоев/нейронов, полиномиальные признаки), добавить новые релевантные признаки, провести \textbf{Feature Engineering}, уменьшить регуляризацию. \textit{Добавление данных скорее всего не поможет.}
            \end{itemize}
        \item \textbf{Признак Переобучения (High Variance):}
            \begin{itemize}
                \item Ошибка на \texttt{Train} низкая, а на \texttt{Valid} значительно выше.
                \item Большой разрыв между кривыми \texttt{Train} и \texttt{Valid}.
                \item \textit{Что делать?} Собрать больше данных, использовать регуляризацию (L1, L2, Dropout), упростить модель (меньше глубина дерева), использовать \textbf{Feature Selection}, использовать ансамбли (Bagging).
            \end{itemize}
        \item \textbf{Хороший баланс:}
            \begin{itemize}
                \item Обе кривые сходятся к низкому значению ошибки.
                \item Разрыв между кривыми небольшой.
            \end{itemize}
    \end{itemize}
    \textit{Умение читать кривые обучения — важный навык для диагностики и улучшения ML моделей!}
    \end{myexampleblock}
    
    % --- Конец контента ---