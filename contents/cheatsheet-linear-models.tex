% >>> Рефакторинг Контента: Линейные Модели v2

% ================================================
% Секция III: Линейная Регрессия
% ================================================
\section{Линейная Регрессия (\texttt{Linear Regression})}

\begin{textbox}{Задача}
    Предсказание \textbf{непрерывного} числового значения (целевой переменной $y$) на основе одного или нескольких признаков ($X$).
    \textit{Примеры: прогнозирование цены дома, температуры, спроса.}
\end{textbox}

\begin{myblock}{Модель Линейной Регрессии}
    Предполагается линейная зависимость между признаками и целевой переменной. Предсказание модели ($\hat{y}$) вычисляется как взвешенная сумма признаков объекта ($\mathbf{x}$) с добавлением свободного члена ($w_0$).
    \[ \hat{y} = w_0 + w_1 x_1 + w_2 x_2 + \dots + w_n x_n = \mathbf{w}^T \mathbf{x} \]
    \begin{itemize}[nosep, leftmargin=*]
        \item $\mathbf{w} = (w_0, w_1, \dots, w_n)$: Вектор \textbf{весов} (параметров) модели, которые нужно найти в процессе обучения. $w_0$ называется \textbf{свободным членом} или \textbf{bias term}.
        \item $\mathbf{x} = (1, x_1, \dots, x_n)$: Вектор \textbf{признаков} объекта, дополненный фиктивным признаком $x_0 = 1$ для удобства матричной записи.
    \end{itemize}
\end{myblock}

\begin{myblock}{Интерпретация Весов}
    Коэффициент $w_j$ при признаке $x_j$ показывает, на сколько \textit{в среднем} изменится предсказание $\hat{y}$, если значение признака $x_j$ увеличить на единицу, при условии, что все остальные признаки остаются неизменными (\textit{ceteris paribus}).
\end{myblock}

\begin{myblock}{Функция Потерь: MSE (\texttt{Mean Squared Error})}
    Для оценки качества модели и её обучения используется \textbf{Среднеквадратичная Ошибка (MSE)}. Она измеряет средний квадрат разности между реальными значениями ($y_i$) и предсказаниями модели ($\hat{y}_i$) по всем $m$ объектам обучающей выборки.
    \[
    MSE(\mathbf{w}) = \frac{1}{m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 = \frac{1}{m} \sum_{i=1}^{m} (y_i - \mathbf{w}^T \mathbf{x}_i)^2
    \]
    \textbf{Цель обучения:} Найти такие веса $\mathbf{w}$, которые минимизируют значение MSE.
    \textbf{Преимущества MSE:}
    \begin{itemize}[nosep, leftmargin=*]
        \item Штрафует большие ошибки сильнее, чем маленькие.
        \item Функция выпуклая и дифференцируемая, что удобно для оптимизации (например, градиентным спуском).
    \end{itemize}
\end{myblock}

% --- Подсекция: Методы Обучения Линейной Регрессии ---
\subsection{Обучение Модели}

\begin{textbox}{Идея Градиентного Спуска (GD)}
    \textbf{Градиентный спуск} — это итеративный алгоритм оптимизации для поиска минимума функции потерь (например, MSE).
    \textbf{Метафора:} Представьте MSE как рельеф местности. Цель — найти самую низкую точку. GD делает это, двигаясь шагами в направлении, противоположном самому крутому склону (анти-градиенту).
    \begin{enumerate}[nosep, leftmargin=*]
        \item Вычислить \textbf{градиент} функции потерь ($\nabla_{\mathbf{w}} MSE$) — вектор, указывающий направление наискорейшего роста функции.
        \item Сделать шаг в \textbf{противоположном} направлении (анти-градиент): $\mathbf{w} := \mathbf{w} - \alpha \nabla_{\mathbf{w}} MSE(\mathbf{w})$.
        \item $\alpha$ — \textbf{скорость обучения} (\textit{learning rate}), гиперпараметр, контролирующий размер шага.
        \item Повторять шаги 1-3 до сходимости (пока веса не перестанут значительно изменяться или не будет достигнуто макс. число итераций).
    \end{enumerate}
\end{textbox}

\begin{myexampleblock}{Варианты Градиентного Спуска}
    Различаются тем, на каком объеме данных вычисляется градиент на каждом шаге:
    \begin{itemize}[nosep, leftmargin=*, itemsep=0.5ex]
        \item \textbf{Batch GD (Пакетный):} Градиент считается по \textbf{всей} обучающей выборке. Точные шаги к минимуму, но может быть очень медленным на больших датасетах.
        \item \textbf{Stochastic GD (Стохастический, SGD):} Градиент считается по \textbf{одному случайно выбранному примеру}. Шаги быстрые, но "шумные", траектория может колебаться вокруг минимума. Подходит для очень больших датасетов и онлайн-обучения.
        \item \textbf{Mini-batch GD (Мини-пакетный):} Градиент считается по небольшой \textbf{случайной подвыборке} (пакету, \textit{batch}) данных (например, 32-512 примеров). Золотая середина: сочетает скорость SGD и стабильность Batch GD. Наиболее часто используемый вариант на практике.
    \end{itemize}
\end{myexampleblock}

\begin{textbox}{Аналитическое Решение (Normal Equation)}
    Для задачи минимизации MSE в линейной регрессии существует \textbf{точное аналитическое решение}, позволяющее найти оптимальные веса $\mathbf{w}^*$ без итераций градиентного спуска.
    \[
    \mathbf{w}^* = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}
    \]
    \begin{itemize}[nosep, leftmargin=*]
        \item $\mathbf{X}$: Матрица признаков (размер $m \times (n+1)$), где строки — объекты, столбцы — признаки (включая столбец единиц для $w_0$).
        \item $\mathbf{y}$: Вектор целевых значений (размер $m \times 1$).
    \end{itemize}
    \textbf{Преимущества:}
    \begin{itemize}[label=\textbullet, nosep, leftmargin=*]
         \item Находит точный минимум MSE за один шаг.
         \item Не требует подбора гиперпараметра learning rate ($\alpha$).
    \end{itemize}
    \textbf{Недостатки:}
    \begin{itemize}[label=\textbullet, nosep, leftmargin=*]
         \item Вычисление обратной матрицы $(\mathbf{X}^T \mathbf{X})^{-1}$ имеет сложность $O(n^3)$, где $n$ — число признаков. Становится непрактичным при очень большом количестве признаков (например, $n > 10,000$).
         \item Матрица $\mathbf{X}^T \mathbf{X}$ может быть \textbf{вырожденной} (сингулярной), если признаки линейно зависимы (мультиколлинеарность) или если число признаков $n$ больше числа объектов $m$. В этом случае обратной матрицы не существует.
    \end{itemize}
\end{textbox}

% --- Подсекция: Предположения и Расширения ---
\subsection{Предположения и Расширения}

\begin{alerttextbox}{Основные Предположения Классической Линейной Регрессии}
    Для корректной интерпретации результатов и построения статистических выводов (например, доверительных интервалов для весов) модель опирается на ряд предположений относительно данных и ошибок модели $\epsilon_i = y_i - \hat{y}_i$:
    \begin{enumerate}[nosep, leftmargin=*]
        \item \textbf{Линейность:} Среднее значение целевой переменной $y$ линейно зависит от признаков $X$.
        \item \textbf{Независимость ошибок:} Ошибки $\epsilon_i$ для разных наблюдений независимы друг от друга.
        \item \textbf{Гомоскедастичность:} Ошибки $\epsilon_i$ имеют одинаковую постоянную дисперсию ($\text{Var}(\epsilon_i) = \sigma^2$) для всех уровней признаков $X$. (Отсутствие гомоскедастичности называется \textit{гетероскедастичностью}).
        \item \textbf{Нормальность ошибок:} Ошибки $\epsilon_i$ распределены нормально с нулевым средним: $\epsilon_i \sim N(0, \sigma^2)$. (Важно в основном для построения доверительных интервалов и проверки гипотез).
        \item \textbf{Отсутствие сильной мультиколлинеарности:} Признаки $x_j$ не должны быть сильно линейно зависимы друг от друга.
    \end{enumerate}
    \textbf{Примечание:} Нарушение этих предположений не всегда делает предсказания модели плохими, но может сделать недействительными статистические выводы о параметрах и их значимости.
\end{alerttextbox}

\begin{myblock}{Полиномиальная Регрессия}
    Стандартная линейная регрессия моделирует только линейные зависимости. Для моделирования нелинейных связей можно использовать \textbf{полиномиальную регрессию}.
    \textbf{Идея:} Создать новые признаки, являющиеся степенями исходных признаков ($x^2, x^3, \dots$) или их произведениями ($x_1 x_2, \dots$). Затем применить обычную линейную регрессию к этому расширенному набору признаков.
    Пример для одного признака $x$:
    \[ \hat{y} = w_0 + w_1 x + w_2 x^2 + \dots + w_d x^d \]
    \textbf{Важно:} Несмотря на нелинейную зависимость от $x$, модель остается \textbf{линейной по параметрам $\mathbf{w}$}, поэтому все методы обучения линейной регрессии применимы.
    \textbf{Риск:} Легко приводит к \textbf{переобучению} при высокой степени полинома $d$. Обычно требует \textbf{регуляризации}.
\end{myblock}

% ================================================
% Секция IV: Логистическая Регрессия
% ================================================
\section{Логистическая Регрессия (\texttt{Logistic Regression})}

\begin{textbox}{Задача}
    Модель для задач \textbf{бинарной классификации}, когда целевая переменная $y$ принимает одно из двух значений (например, 0 или 1, "да"/"нет", "спам"/"не спам").
\end{textbox}

\begin{myblock}{Основная Идея}
    Логистическая регрессия напрямую предсказывает не сам класс, а \textbf{вероятность} принадлежности объекта к классу 1, $P(y=1 | \mathbf{x})$.
    \begin{itemize}[nosep, leftmargin=*]
        \item Сначала вычисляется линейная комбинация признаков: $z = \mathbf{w}^T \mathbf{x}$.
        \item Затем результат $z$ (который может быть любым числом) преобразуется в вероятность (число от 0 до 1) с помощью \textbf{сигмоидной (логистической) функции} $\sigma(z)$.
    \end{itemize}
\end{myblock}

\begin{myblock}{Сигмоидная Функция}
    \[ \sigma(z) = \frac{1}{1 + e^{-z}} \]
    \textbf{Свойства:}
    \begin{itemize}[nosep, leftmargin=*]
        \item Принимает значения строго между 0 и 1.
        \item Если $z \to +\infty$, то $\sigma(z) \to 1$.
        \item Если $z \to -\infty$, то $\sigma(z) \to 0$.
        \item Если $z = 0$, то $\sigma(z) = 0.5$.
    \end{itemize}
    Предсказание вероятности: $\hat{p} = P(y=1 | \mathbf{x}) = \sigma(\mathbf{w}^T \mathbf{x})$.
\end{myblock}

\begin{textbox}{Принятие Решения о Классе}
    Получив предсказанную вероятность $\hat{p}$, решение о классе принимается сравнением с \textbf{порогом} (threshold), обычно равным 0.5:
    \[ \hat{y} =
       \begin{cases}
           1, & \text{если } \hat{p} \ge 0.5 \\
           0, & \text{если } \hat{p} < 0.5
       \end{cases}
    \]
    Порог можно настраивать в зависимости от задачи (например, если важнее минимизировать ложноотрицательные срабатывания).
\end{textbox}

\begin{myblock}{Функция Потерь: LogLoss (Бинарная Кросс-Энтропия)}
    MSE не подходит для задач классификации с вероятностными выходами. Вместо неё используется \textbf{LogLoss} или \textbf{Бинарная Кросс-Энтропия}.
    \[
    LogLoss(\mathbf{w}) = -\frac{1}{m} \sum_{i=1}^{m} [ y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i) ]
    \]
    Где $y_i$ — истинный класс (0 или 1), $\hat{p}_i = \sigma(\mathbf{w}^T \mathbf{x}_i)$ — предсказанная вероятность класса 1.
    \textbf{Интуиция:}
    \begin{itemize}[nosep, leftmargin=*]
        \item Если истинный класс $y_i=1$, член $(1-y_i)\log(1-\hat{p}_i)$ обнуляется, и штраф равен $- \log(\hat{p}_i)$. Штраф тем больше, чем меньше предсказанная вероятность $\hat{p}_i$.
        \item Если истинный класс $y_i=0$, член $y_i\log(\hat{p}_i)$ обнуляется, и штраф равен $- \log(1 - \hat{p}_i)$. Штраф тем больше, чем больше предсказанная вероятность $\hat{p}_i$ (т.е., чем меньше $1-\hat{p}_i$).
    \end{itemize}
    Модель сильно штрафуется за уверенные, но неверные предсказания. Обучение также проводится с помощью вариантов градиентного спуска для минимизации LogLoss.
\end{myblock}

\begin{myexampleblock}{Мультиклассовая Классификация: Softmax Regression}
    Для задач с $K > 2$ классами используется обобщение логистической регрессии — \textbf{Softmax Regression} (или Multinomial Logistic Regression).
    \begin{itemize}[nosep, leftmargin=*]
        \item Для каждого класса $k \in \{1, \dots, K\}$ вычисляется своя линейная комбинация ("оценка"): $z_k = \mathbf{w}_k^T \mathbf{x}$.
        \item Эти оценки преобразуются в вектор вероятностей $\hat{\mathbf{p}}$ с помощью \textbf{функции Softmax}:
          \[ P(y=k | \mathbf{x}) = \hat{p}_k = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}} \]
        \item Функция Softmax гарантирует, что $\hat{p}_k \in (0, 1)$ и $\sum_{k=1}^{K} \hat{p}_k = 1$.
        \item Предсказанным классом обычно является тот, для которого вероятность $\hat{p}_k$ максимальна.
        \item Функция потерь — \textbf{Cross-Entropy Loss} (обобщение LogLoss на мультиклассовый случай).
    \end{itemize}
\end{myexampleblock}

% ================================================
% Секция V: Регуляризация Линейных Моделей
% ================================================
\section{Регуляризация L1 и L2}

\begin{alerttextbox}{Проблема: Переобучение (Overfitting)}
    Сложные модели (например, полиномиальная регрессия высокой степени или модели с большим количеством признаков) могут \textbf{переобучаться} — идеально подгоняться под обучающие данные, включая шум, но плохо обобщаться на новые, невиданные данные. Визуально это проявляется в очень низких потерях на обучении и высоких на валидации/тесте. Одним из признаков переобучения часто являются \textit{слишком большие значения весов} $\mathbf{w}$.
\end{alerttextbox}

\begin{textbox}{Идея Регуляризации}
    \textbf{Регуляризация} — это метод борьбы с переобучением путем добавления \textbf{штрафа} к функции потерь модели за величину её весов. Это заставляет модель искать баланс между минимизацией исходной ошибки (MSE или LogLoss) и поддержанием весов небольшими.
    Общая формула регуляризованной функции потерь:
    \[ J_{reg}(\mathbf{w}) = J_{original}(\mathbf{w}) + \lambda \cdot R(\mathbf{w}) \]
    \begin{itemize}[nosep, leftmargin=*]
        \item $J_{original}(\mathbf{w})$: Исходная функция потерь (MSE для регрессии, LogLoss для классификации).
        \item $R(\mathbf{w})$: \textbf{Регуляризационный член}, зависящий от весов модели.
        \item $\lambda \ge 0$: \textbf{Коэффициент регуляризации} (гиперпараметр). Контролирует силу штрафа.
            \begin{itemize}[label=\textbullet, nosep]
                \item $\lambda = 0$: Нет регуляризации.
                \item $\lambda \to \infty$: Веса стремятся к нулю, модель становится очень простой (может привести к недообучению).
            \end{itemize}
    \end{itemize}
    Оптимальное значение $\lambda$ подбирается с помощью кросс-валидации.
\end{textbox}

\begin{myblock}{Важность Масштабирования Признаков}
    Перед применением регуляризации \textbf{крайне рекомендуется} \textbf{масштабировать} (привести к одному масштабу) признаки $X$. Популярные методы:
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Стандартизация (StandardScaler):} Приведение к нулевому среднему и единичной дисперсии.
        \item \textbf{Нормализация (MinMaxScaler):} Приведение к диапазону [0, 1] или [-1, 1].
    \end{itemize}
    \textbf{Зачем?} Регуляризационный штраф $R(\mathbf{w})$ зависит от абсолютных значений весов. Если признаки имеют разный масштаб (например, возраст в годах и доход в рублях), то веса при признаках с большим масштабом будут искусственно занижаться, а при признаках с малым — завышаться, что исказит эффект регуляризации.
    \textbf{Примечание:} Свободный член $w_0$ обычно \textbf{не регуляризуют}, так как он отвечает за общее смещение модели, а не за взаимодействие с признаками.
\end{myblock}

\begin{myblock}{L2 Регуляризация (Ridge / Гребневая Регрессия)}
    Использует в качестве штрафа \textbf{сумму квадратов} весов (L2-норму вектора весов).
    \[ R_{L2}(\mathbf{w}) = \sum_{j=1}^{n} w_j^2 = ||\mathbf{w}||_2^2 \]
    (Сумма идет от $j=1$, так как $w_0$ не регуляризуется).
    \textbf{Функция потерь (пример для MSE):}
    \[ J_{Ridge}(\mathbf{w}) = MSE(\mathbf{w}) + \lambda \sum_{j=1}^{n} w_j^2 \]
    \textbf{Эффект:}
    \begin{itemize}[nosep, leftmargin=*]
        \item "Сжимает" веса $\mathbf{w}$, делая их значения \textbf{меньше}.
        \item Уменьшает веса пропорционально их величине (большие веса штрафуются сильнее).
        \item Редко приводит к обнулению весов (веса становятся маленькими, но не нулевыми).
        \item Делает решение более устойчивым, особенно при наличии мультиколлинеарности.
        \item Является хорошим выбором по умолчанию.
    \end{itemize}
\end{myblock}

\begin{myblock}{L1 Регуляризация (Lasso / Least Absolute Shrinkage and Selection Operator)}
    Использует в качестве штрафа \textbf{сумму модулей} весов (L1-норму вектора весов).
    \[ R_{L1}(\mathbf{w}) = \sum_{j=1}^{n} |w_j| = ||\mathbf{w}||_1 \]
    (Сумма идет от $j=1$, так как $w_0$ не регуляризуется).
    \textbf{Функция потерь (пример для MSE):}
    \[ J_{Lasso}(\mathbf{w}) = MSE(\mathbf{w}) + \lambda \sum_{j=1}^{n} |w_j| \]
    \textbf{Эффект:}
    \begin{itemize}[nosep, leftmargin=*]
        \item Также "сжимает" веса $\mathbf{w}$ к нулю.
        \item Из-за использования модуля, может \textbf{обнулять} некоторые веса (при достаточно большом $\lambda$).
        \item Эффективно производит \textbf{отбор признаков} (\textit{feature selection}), оставляя только наиболее важные.
        \item Полезна, когда есть основания полагать, что многие признаки являются неинформативными.
    \end{itemize}
    \textbf{Примечание:} Функция потерь с L1-штрафом не дифференцируема в точке 0, что требует использования специальных методов оптимизации (например, Subgradient descent или Proximal gradient descent).
\end{myblock}

\begin{myexampleblock}{Elastic Net}
    Комбинация L1 и L2 регуляризации. Штраф является взвешенной суммой L1 и L2 норм.
    \[ R_{ElasticNet}(\mathbf{w}) = \alpha \sum_{j=1}^{n} |w_j| + \frac{1-\alpha}{2} \sum_{j=1}^{n} w_j^2 \]
    (Здесь $\alpha$ - это \textit{другой} гиперпараметр, смешивающий L1 и L2, часто обозначаемый как `l1\_ratio`, не путать со скоростью обучения. Общий коэффициент регуляризации $\lambda$ также присутствует).
    Сочетает преимущества обоих подходов: отбирает признаки (как Lasso) и стабилизирует решение при коррелирующих признаках (как Ridge).
\end{myexampleblock}

\begin{alerttextbox}{Регуляризация и Дилемма Смещения-Разброса}
    Регуляризация является явным способом управления компромиссом Bias-Variance:
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Увеличение $\lambda$ (усиление регуляризации):}
            \begin{itemize}[label=\textbullet, nosep]
                 \item Увеличивает \textbf{смещение (Bias)}: Модель становится проще, может хуже описывать обучающие данные.
                 \item Уменьшает \textbf{разброс (Variance)}: Модель становится менее чувствительной к шуму в данных и лучше обобщается.
            \end{itemize}
        \item \textbf{Уменьшение $\lambda$ (ослабление регуляризации):}
            \begin{itemize}[label=\textbullet, nosep]
                 \item Уменьшает \textbf{смещение (Bias)}: Модель становится сложнее, лучше подгоняется под обучающие данные.
                 \item Увеличивает \textbf{разброс (Variance)}: Повышается риск переобучения.
            \end{itemize}
    \end{itemize}
    Цель — найти такое $\lambda$, которое минимизирует ошибку на \textit{новых} (валидационных) данных, достигая оптимального баланса между смещением и разбросом.
\end{alerttextbox}