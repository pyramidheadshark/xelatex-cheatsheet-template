% >>> Контент для шпаргалки "Cheatsheet 2: Оценка Моделей - Метрики и Валидация" v4

% ================================================
% Секция I: Метрики Оценки Задач Регрессии
% ================================================
\section{Метрики Оценки Задач Регрессии}

\begin{myblock}{Зачем нужны метрики регрессии?}
    Метрики — это численные показатели для **объективной оценки качества** модели регрессии (предсказание непрерывного значения). Они показывают, насколько хорошо предсказания модели ($\hat{y}_i$) соответствуют истинным значениям ($y_i$).
\end{myblock}

\begin{textbox}{{MAE (Mean Absolute Error) / Средняя Абсолютная Ошибка}}
    \[ MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| \]
    \textit{Описание:} Среднее абсолютное отклонение предсказаний от факта.
    \textit{Интерпретация:} Показывает среднюю ошибку в единицах целевой переменной. Например, MAE = 10 означает, что модель в среднем ошибается на 10 единиц (рублей, градусов и т.д.).
    \textit{Свойства:} Менее чувствительна к выбросам, чем MSE/RMSE.
    \textit{Предпочтительна:} Когда важна прямая интерпретация ошибки и устойчивость к выбросам.
\end{textbox}

\begin{textbox}{{MSE (Mean Squared Error) / Среднеквадратичная Ошибка}}
    \[ MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \]
    \textit{Описание:} Среднее квадратов отклонений предсказаний от факта.
    \textit{Интерпретация:} Единицы измерения - квадрат исходных единиц (сложно интерпретировать напрямую).
    \textit{Свойства:} Сильно штрафует за большие ошибки из-за возведения в квадрат. Дифференцируема, часто используется как функция потерь при обучении.
    \textit{Предпочтительна:} Когда большие ошибки крайне нежелательны; удобна для оптимизации.
\end{textbox}

\begin{textbox}{{RMSE (Root Mean Squared Error) / Корень из Среднеквадратичной Ошибки}}
    \[ RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \]
    \textit{Описание:} Корень квадратный из MSE.
    \textit{Интерпретация:} Возвращает метрику к исходным единицам измерения (как MAE), что упрощает интерпретацию. RMSE всегда больше или равен MAE.
    \textit{Свойства:} Чувствительна к выбросам (но меньше, чем MSE). Штрафует большие ошибки сильнее, чем MAE.
    \textit{Предпочтительна:} Когда нужна интерпретация в исходных единицах, но с большим штрафом за большие ошибки, чем у MAE.
\end{textbox}

\begin{textbox}{{R² (Коэффициент Детерминации)}}
    \[ R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} = 1 - \frac{MSE}{\text{Var}(y)} \]
    \textit{Описание:} Доля дисперсии зависимой переменной ($y$), объясненная моделью.
    \textit{Интерпретация:} Варьируется от $(-\infty)$ до 1. Ближе к 1 — лучше. $R^2=0.7$ означает, что модель объясняет 70% изменчивости целевой переменной. $R^2=0$: модель не лучше константного предсказания среднего ($\bar{y}$). $R^2<0$: модель хуже среднего.
    \textit{Свойства:} Увеличивается при добавлении любых признаков (даже бесполезных). Используйте \textbf{Adjusted R²} для учета количества признаков при сравнении моделей.
    \textit{Предпочтительна:} Для оценки объяснительной силы модели.
\end{textbox}

% ================================================
% Секция II: Метрики Оценки Задач Классификации
% ================================================
\section{Метрики Оценки Задач Классификации}

\subsection{Матрица ошибок (Confusion Matrix)}
\begin{myblock}{{Основа для метрик бинарной классификации}}
    Матрица ошибок показывает распределение предсказаний модели по сравнению с истинными метками классов. Обычно класс "1" считается положительным (positive, e.g., "болезнь", "спам", "мошенничество"), а класс "0" - отрицательным (negative).

    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{TP (True Positive)}: Истинно положительные. Объект класса 1, предсказан как 1. (Верно найден больной).
        \item \textbf{TN (True Negative)}: Истинно отрицательные. Объект класса 0, предсказан как 0. (Верно найден здоровый).
        \item \textbf{FP (False Positive)}: Ложно положительные. \textbf{Ошибка I рода}. Объект класса 0, предсказан как 1. (Здоровый ошибочно признан больным).
        \item \textbf{FN (False Negative)}: Ложно отрицательные. \textbf{Ошибка II рода}. Объект класса 1, предсказан как 0. (Больной ошибочно признан здоровым).
    \end{itemize}
    \vspace{1ex}
    \textbf{Структура Матрицы Ошибок:}
    \vspace{0.5ex}
    \begin{center}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{cc|c|c|c}
         & & \multicolumn{2}{c|}{\textbf{Предсказанный класс}} & \textbf{Всего (Реальность)} \\ \cline{3-4}
         & & \textbf{1 (Positive)} & \textbf{0 (Negative)} & \\ \hline
        \multirow{2}{*}{\rotatebox[origin=c]{90}{\textbf{Истинный класс}}}
        & \textbf{1 (Positive)} & TP & FN & P = TP + FN \\ \cline{2-5}
        & \textbf{0 (Negative)} & FP & TN & N = FP + TN \\ \hline
        & \textbf{Всего (Предсказание)} & \^{P} = TP + FP & \^{N} = FN + TN & \textbf{Total = P+N} \\
    \end{tabular}
    \end{center}
    \vspace{1ex}
\end{myblock}

\subsection{Основные Метрики Классификации}

\begin{textbox}{{Accuracy (Доля правильных ответов)}}
    \[ \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{\text{Верные предсказания}}{\text{Все предсказания}} \]
    \textit{Описание:} Общая доля верных предсказаний модели.
    \textit{Проблема:} \textbf{Неинформативна при сильном дисбалансе классов!} Модель, всегда предсказывающая мажоритарный класс, будет иметь высокую Accuracy, но будет бесполезна.
\end{textbox}

\begin{textbox}{{Precision (Точность)}}
    \[ \text{Precision} = \frac{TP}{TP + FP} = \frac{\text{Верно найденные позитивные}}{\text{Все объекты, названные позитивными}} \]
    \textit{Вопрос:} "Из тех, кого мы назвали классом 1, какая доля действительно принадлежит классу 1?"
    \textit{Важность:} Высока, когда цена \textbf{FP} (Ошибка I рода) велика (e.g., неверный диагноз здоровому, блокировка честного клиента).
\end{textbox}

\begin{textbox}{{Recall (Полнота, Sensitivity, True Positive Rate - TPR)}}
    \[ \text{Recall} = \frac{TP}{TP + FN} = \frac{\text{Верно найденные позитивные}}{\text{Все реальные позитивные объекты (P)}} \]
    \textit{Вопрос:} "Какую долю реальных объектов класса 1 мы смогли обнаружить?"
    \textit{Важность:} Высока, когда цена \textbf{FN} (Ошибка II рода) велика (e.g., пропуск больного, пропуск мошенника).
\end{textbox}

\begin{textbox}{{F1-мера (F1-Score)}}
    \[ F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2TP}{2TP + FP + FN} \]
    \textit{Описание:} Гармоническое среднее Precision и Recall. Полезна, когда важен баланс между ними.
    \textit{Свойство:} Близка к нулю, если хотя бы одна из компонент (Precision или Recall) близка к нулю.
    \textit{Обобщение:} \textbf{$F_\beta$-мера} позволяет придать больший вес Recall ($\beta > 1$) или Precision ($\beta < 1$).
    \[ F_\beta = (1 + \beta^2) \cdot \frac{\text{Precision} \cdot \text{Recall}}{(\beta^2 \cdot \text{Precision}) + \text{Recall}} \]
\end{textbox}

\begin{textbox}{{Specificity (Специфичность, True Negative Rate - TNR)}}
     \[ \text{Specificity} = \frac{TN}{TN + FP} = \frac{\text{Верно найденные негативные}}{\text{Все реальные негативные объекты (N)}} \]
    \textit{Вопрос:} "Какую долю реальных объектов класса 0 мы правильно определили как класс 0?"
    \textit{Связь:} Часто используется в паре с Recall (Sensitivity) в медицине.
\end{textbox}

\begin{textbox}{{False Positive Rate (FPR)}}
    \[ \text{FPR} = \frac{FP}{TN + FP} = \frac{\text{Ложно названные позитивными}}{\text{Все реальные негативные объекты (N)}} = 1 - \text{Specificity} \]
    \textit{Вопрос:} "Какую долю объектов класса 0 модель ошибочно назвала классом 1?"
    \textit{Использование:} Используется как ось X в ROC-кривой.
\end{textbox}

\begin{myblock}{Компромисс Precision-Recall}
    Часто существует обратная зависимость между Precision и Recall при изменении порога классификации модели.
    \begin{itemize}[nosep, leftmargin=*]
        \item Увеличение порога $\implies$ меньше объектов объявляются классом 1 $\implies$ FP уменьшается (растет Precision), но TP тоже может уменьшиться (падает Recall).
        \item Уменьшение порога $\implies$ больше объектов объявляются классом 1 $\implies$ TP растет (растет Recall), но FP тоже может вырасти (падает Precision).
    \end{itemize}
    Выбор оптимального порога зависит от задачи и баланса между Precision и Recall (часто максимизируют F1 или выбирают порог на PR-кривой).
\end{myblock}

\subsection{Метрики для Оценки Ранжирования}

\begin{myexampleblock}{{ROC AUC (Receiver Operating Characteristic Area Under Curve)}}
    Метрика, оценивающая качество модели как бинарного классификатора \textbf{независимо от порога классификации}. Показывает, насколько хорошо модель способна \textbf{ранжировать} объекты.

    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{ROC-кривая}: График \textbf{TPR (Recall)} vs \textbf{FPR} при изменении порога от 1 до 0.
        \item \textbf{AUC}: Площадь под ROC-кривой (от 0 до 1).
            \begin{itemize}
                \item AUC = 1: Идеал.
                \item AUC = 0.5: Случайность.
                \item AUC < 0.5: Хуже случайности.
            \end{itemize}
        \item \textbf{Интерпретация AUC}: Вероятность, что случайный объект класса 1 получит скор выше, чем случайный объект класса 0.
        \item \textbf{Свойства}: Относительно устойчив к дисбалансу классов. Сравнивает модели по общей ранжирующей способности.
    \end{itemize}
    \textit{Аналогия}: Насколько хорошо модель отделяет "больных" от "здоровых" при сортировке.

    \begin{center}
    \begin{tikzpicture}
        \begin{axis}[roc curve style, title={Пример ROC-кривой}]
        \addplot coordinates { (0,0) (0.1,0.5) (0.2,0.8) (0.4,0.9) (0.6,0.95) (0.8,0.98) (1,1) };
        \addlegendentry{Хорошая модель (AUC $\approx$ 0.9)}
        \addplot[dashed, color=gray] coordinates {(0,0) (1,1)};
        \addlegendentry{Случайная модель (AUC = 0.5)}
        \end{axis}
    \end{tikzpicture}
    \end{center}
\end{myexampleblock}

\begin{myexampleblock}{{Precision-Recall AUC (PR AUC)}}
    Альтернатива ROC AUC, особенно полезная при \textbf{сильном дисбалансе классов} и фокусе на \textbf{положительном (миноритарном) классе}.

    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{PR-кривая}: График \textbf{Precision} vs \textbf{Recall (TPR)} при изменении порога.
        \item \textbf{PR AUC}: Площадь под PR-кривой (от 0 до 1). Выше - лучше.
        \item \textbf{Приоритет при дисбалансе}: Более чувствительна к FP, чем ROC AUC. Сравнивает модели по способности находить позитивные примеры с высокой точностью.
        \item \textbf{Baseline}: Равен доле позитивного класса $P/(P+N)$. Низкий baseline при дисбалансе делает PR AUC более показательным для оценки улучшения.
    \end{itemize}
    \textit{Аналогия}: Насколько точно мы находим "иголки" (класс 1), когда пытаемся найти разную их долю (Recall) в "стоге сена" (все данные)?

    \begin{center}
    \begin{tikzpicture}
        \begin{axis}[pr curve style, title={Пример PR-кривой (Сильный дисбаланс)}]
        \addplot coordinates { (0.0,1.0) (0.1,0.95) (0.2,0.85) (0.3,0.7) (0.4,0.5) (0.5,0.35) (0.6,0.25) (0.7,0.18) (0.8,0.12) (0.9,0.08) (1.0,0.05) };
        \addlegendentry{Модель}
        \addplot[dashed, color=gray] coordinates {(0, 0.05) (1, 0.05)};
        \addlegendentry{Baseline (случ.) $\approx$ 0.05}
        \end{axis}
    \end{tikzpicture}
    \end{center}
\end{myexampleblock}

\subsection{Выбор Метрики Классификации}
\begin{alerttextbox}{Ключевой Аспект: Бизнес-Задача}
    Выбор основной метрики \textbf{критически зависит от бизнес-задачи} и стоимости ошибок FP и FN.

    \begin{itemize}[itemsep=1ex, leftmargin=*]
        \item \textbf{Задача: Диагностика опасной болезни}
            \textit{Цель:} Не пропустить больных (максимизировать \textbf{Recall}).
            \textit{Метрики:} Recall, F-мера ($\beta > 1$), PR AUC.
        \item \textbf{Задача: Спам-фильтр}
            \textit{Цель:} Не терять важные письма (максимизировать \textbf{Precision}).
            \textit{Метрики:} Precision, F-мера ($\beta < 1$).
        \item \textbf{Задача: CTR prediction}
            \textit{Цель:} Точное ранжирование и калибровка вероятностей.
            \textit{Метрики:} \textbf{ROC AUC}, \textbf{LogLoss}.
        \item \textbf{Задача: Поиск мошенников (дисбаланс)}
            \textit{Цель:} Баланс между поиском мошенников (Recall) и точностью (Precision). Accuracy бесполезна.
            \textit{Метрики:} \textbf{F1-Score}, \textbf{PR AUC}, анализ матрицы ошибок.
    \end{itemize}
    \textbf{Вывод:} Всегда обсуждайте с заказчиком последствия ошибок FP и FN для выбора адекватной метрики. Часто нужно отслеживать несколько метрик.
\end{alerttextbox}

\subsection{Offline vs Online Метрики}
\begin{myblock}{Где и как измеряем качество}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Offline метрики}: Расчет на отложенной выборке (Test set, CV folds). Примеры: Accuracy, F1, AUC, MSE. Назначение: разработка, валидация, выбор модели.
        \item \textbf{Online метрики}: Расчет на реальных данных в production. Примеры: CTR, конверсия, доход. Назначение: оценка реального бизнес-эффекта, A/B тестирование.
    \end{itemize}
    \textbf{Важно:} Улучшение offline-метрик не всегда гарантирует улучшение online-метрик.
\end{myblock}

% ================================================
% Секция III: Статистические Основы Оценки
% ================================================
\section{Статистические Основы Оценки}

\begin{alerttextbox}{Зачем нужна статистика в ML?}
Работа с \textbf{ограниченными выборками} данных означает, что любая посчитанная метрика — это лишь \textbf{оценка} истинного значения. Статистика помогает:
\begin{itemize}[nosep, leftmargin=*]
    \item Оценить \textbf{неопределенность} измерений (точность оценки).
    \item Проверить \textbf{надежность} выводов (значимость различий).
    \item Принимать обоснованные решения.
\end{itemize}
\end{alerttextbox}

\subsection{Дисперсия и Стандартное Отклонение Данных}
\begin{textbox}{Измерение Разброса Данных}
\textbf{Дисперсия (Variance, $s^2$)}: Мера разброса значений относительно среднего ($\bar{x}$).
\[ s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2 \]
\textbf{Стандартное отклонение (Standard Deviation, SD, s)}: Корень из дисперсии ($s = \sqrt{s^2}$). Измеряется в исходных единицах.

\textbf{Интуиция:} Низкая дисперсия/SD $\implies$ данные сгруппированы. Высокая $\implies$ данные разбросаны.

\textbf{Применение в ML:} Анализ изменчивости данных, оценка стабильности метрик на CV (SD по фолдам), компонент R², стандартной ошибки (SE).
\end{textbox}

\subsection{Доверительные Интервалы (Confidence Intervals, CI)}

\begin{textbox}{Что такое Доверительный Интервал?}
    CI — это диапазон значений, который с заданной \textbf{уверенностью} (e.g., 95\%) содержит \textbf{истинное значение} параметра (e.g., истинный средний AUC), оцененного по выборке.

    \textbf{Построение (схематично):}
    \[ CI = [\text{Оценка} - \text{Погрешность}, \quad \text{Оценка} + \text{Погрешность}] \]
    \[ \text{Погрешность (Margin of Error)} = \text{Крит. Значение} \times \text{Стандартная Ошибка (SE)} \]
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Оценка}: Значение метрики по выборке (e.g., среднее по фолдам CV).
        \item \textbf{Крит. Значение}: Зависит от уровня доверия и распределения (e.g., $\approx 1.96$ для 95\% CI, нормальное распределение).
        \item \textbf{SE (Standard Error)}: Точность оценки (e.g., $SE = SD/\sqrt{n}$ для среднего).
    \end{itemize}
\end{textbox}

\begin{textbox}{Интерпретация и Применение CI в ML}
    \textbf{Интерпретация 95\% CI [A, B]:} "Мы на 95\% уверены, что истинное значение параметра находится между A и B."

    \textbf{Применение:}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Оценка надежности:} Широкий CI $\implies$ большая неопределенность.
        \item \textbf{Сравнение моделей/групп:} Строим CI для \textbf{разницы} метрик ($\text{metric}_B - \text{metric}_A$).
            \begin{itemize}
                \item Если CI \textbf{не включает 0} (e.g., [0.01, 0.05]): разница статистически значима на выбранном уровне.
                \item Если CI \textbf{включает 0} (e.g., [-0.02, 0.03]): нет оснований утверждать о значимой разнице.
            \end{itemize}
    \end{itemize}
\end{textbox}

\subsection{Проверка Статистических Гипотез и p-value}
\begin{myblock}{Процесс Проверки Статистических Гипотез}
Цель: определить, является ли наблюдаемый эффект реальным или случайным.
\textbf{Шаги:}
\begin{enumerate}[nosep, leftmargin=*]
    \item \textbf{Формулировка Гипотез:}
        \begin{itemize}
            \item $H_0$ (Нулевая): Гипотеза об отсутствии эффекта (e.g., $\mu_A = \mu_B$).
            \item $H_1$ (Альтернативная): Гипотеза о наличии эффекта (e.g., $\mu_A \neq \mu_B$ или $\mu_B > \mu_A$).
        \end{itemize}
    \item \textbf{Выбор Уровня Значимости ($\alpha$):} Порог ошибки I рода (обычно 0.05).
    \item \textbf{Расчет Статистики Теста:} Мера отклонения данных от $H_0$.
    \item \textbf{Расчет p-value.}
\end{enumerate}
\end{myblock}

\begin{textbox}{{P-value (P-значение)}}
    \textbf{Определение:} Вероятность получить наблюдаемые данные (или еще более экстремальные), \textbf{если предположить, что $H_0$ верна}.

    \textbf{Правило принятия решения:}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{p-value < $\alpha$}: Отвергаем $H_0$. Результат статистически значим. (Данные маловероятны при $H_0$).
        \item \textbf{p-value $\ge$ $\alpha$}: Не отвергаем $H_0$. Результат не является статистически значимым. (Данные совместимы с $H_0$).
    \end{itemize}
    \textbf{Важно:} Не отвергнуть $H_0$ не значит доказать её истинность!
\end{textbox}

\begin{myblock}{Типы Ошибок при Проверке Гипотез}
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{Ошибка I рода ($\alpha$)}: Отвергнуть $H_0$, когда она верна (False Positive). Вероятность $\le \alpha$.
    \item \textbf{Ошибка II рода ($\beta$)}: Не отвергнуть $H_0$, когда она ложна (False Negative).
    \item \textbf{Мощность теста (Power = $1-\beta$)}: Вероятность правильно отвергнуть ложную $H_0$ (обнаружить реальный эффект).
\end{itemize}
\end{myblock}

\subsection{Основные Статистические Тесты для Сравнения}
\begin{myblock}{Выбор подходящего теста}
Зависит от: цели, числа групп, зависимости выборок, типа и распределения данных, размера выборки.
\end{myblock}

\begin{myexampleblock}{{Z-тест (для средних или долей)}}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Применение}: Сравнение долей (конверсий, CTR) в A/B тестах.
        \item \textbf{Предположения}: Очень большие выборки ($n > 30..50$, часто тысячи).
    \end{itemize}
\end{myexampleblock}

\begin{myexampleblock}{{T-тест (для средних)}}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Применение}: Сравнение средних (метрики, бизнес-показатели).
        \item \textbf{Предположения}: Данные примерно нормальны (или $n \ge 15..30$); дисперсии неизвестны. Используется Welch's t-test по умолчанию для независимых выборок.
        \item \textbf{Виды:}
            \begin{itemize}
                \item \textit{Независимый}: Сравнение средних 2х независимых групп (A/B тест).
                \item \textit{Парный}: \textbf{Критичен для ML!} Сравнение метрик 2х моделей на \textbf{одних и тех же фолдах CV}. Тестирует $H_0: \mu_{\text{diff}} = 0$.
            \end{itemize}
    \end{itemize}
\end{myexampleblock}

\begin{myexampleblock}{{Тест Манна-Уитни (Mann-Whitney U / Wilcoxon Rank-Sum)}}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Применение}: Сравнение распределений/медиан 2х \textbf{независимых} выборок. Непараметрический аналог независимого t-теста.
        \item \textbf{Предположения}: Независимые выборки, данные мин. порядковые. \textbf{Нормальность не требуется!}
        \item \textbf{Использование в ML}: A/B тесты с ненормальными данными (время на сайте, доход).
        \item \textbf{Парный аналог (для ненормальных парных данных)}: \textbf{Тест Уилкоксона для связанных выборок (Wilcoxon signed-rank test)}. Можно использовать для сравнения моделей на фолдах CV, если разности метрик не нормальны.
    \end{itemize}
\end{myexampleblock}

\begin{myblock}{Резюме по Статистике}
Стат. инструменты (CI, тесты) нужны для оценки надежности метрик и значимости различий между моделями/группами.
\end{myblock}

% ================================================
% Секция IV: Практические Аспекты Валидации и Оценки
% ================================================
\section{Практические Аспекты Валидации и Оценки}

\subsection{Кросс-валидация (Cross-Validation, CV)}

\begin{myblock}{Общая Идея Кросс-валидации}
Метод оценки обобщающей способности модели на независимых данных и получения более надежной оценки метрики, чем на единственном test-сплите. Используется для оценки модели и настройки гиперпараметров.
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{Принцип:} Обучающая выборка многократно делится на train fold и validation fold. Модель обучается на train fold, оценивается на validation fold. Процесс повторяется.
    \item \textbf{Результат:} Набор оценок метрики (по одной на фолд). Итоговая оценка - среднее по фолдам. Стандартное отклонение по фолдам показывает стабильность.
\end{itemize}
\end{myblock}

\begin{myexampleblock}{K-Fold CV}
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{Метод:} Данные делятся на $K$ фолдов. На итерации $k$, модель обучается на $K-1$ фолдах, валидируется на $k$-ом фолде. Повторяется $K$ раз.
    \item \textbf{Параметры:} Обычно $K=5$ или $K=10$.
    \item \textbf{Применение:} Стандартный метод для регрессии и классификации (при балансе классов).
\end{itemize}
\end{myexampleblock}

\begin{myexampleblock}{Stratified K-Fold CV}
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{Метод:} Модификация K-Fold для \textbf{классификации}. Гарантирует сохранение \textbf{соотношения классов} в каждом фолде.
    \item \textbf{Применение:} \textbf{Обязательно использовать при дисбалансе классов}. Рекомендуется по умолчанию для задач классификации.
\end{itemize}
\end{myexampleblock}

\begin{myexampleblock}{{Leave-One-Out CV (LOOCV)}}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Метод:} K-Fold с $K=n$ (число объектов). Обучение на $n-1$, валидация на 1.
        \item \textbf{Плюсы:} Почти несмещенная оценка ошибки.
        \item \textbf{Минусы:} Вычислительно дорого, высокая дисперсия оценки.
        \item \textbf{Применение:} Очень маленькие датасеты.
    \end{itemize}
\end{myexampleblock}

\begin{myexampleblock}{{Time Series CV (Кросс-валидация для Временных Рядов)}}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Проблема:} Стандартный K-Fold нарушает временную структуру ("заглядывание в будущее").
        \item \textbf{Методы:} Используются схемы, сохраняющие порядок данных:
            \begin{itemize}
                 \item \textbf{Rolling / Sliding Window:} Обучение на окне данных, валидация на следующем блоке. Окно сдвигается вперед.
                 \item \textbf{Expanding Window:} Обучение на всех данных до точки $t$, валидация на следующем блоке. Обучающая выборка растет.
            \end{itemize}
        \item \textbf{Применение:} Задачи прогнозирования временных рядов.
    \end{itemize}
\end{myexampleblock}

\subsection{Работа с Несбалансированными Данными}
\begin{myblock}{Проблема Дисбаланса Классов}
Ситуация значительного преобладания одного класса над другим(и).
\textbf{Основные Проблемы:} Неинформативность Accuracy, игнорирование миноритарного класса моделью, проблемы с валидацией (K-Fold).
\end{myblock}

\begin{myblock}{Подход 1: Использовать Адекватные Метрики}
Фокусироваться на метриках, чувствительных к ошибкам на миноритарном классе:
\begin{itemize}[nosep, leftmargin=*]
    \item \textbf{Precision, Recall, F1-Score}
    \item \textbf{ROC AUC} (но может быть обманчив при сильном дисбалансе)
    \item \textbf{PR AUC} (часто более предпочтителен при сильном дисбалансе)
    \item Анализ \textbf{Матрицы ошибок}.
\end{itemize}
\end{myblock}

\begin{myblock}{{Подход 2: Изменение Выборки (Resampling)}}
    Применяется \textbf{только к обучающим данным внутри фолдов CV!}
    \begin{itemize}[nosep, leftmargin=*]
        \item \textbf{Undersampling}: Удаление части мажоритарного класса (Random, NearMiss). \textit{Риск:} Потеря информации.
        \item \textbf{Oversampling}: Увеличение миноритарного класса.
            \begin{itemize}
                \item \textit{Random Oversampling:} Дублирование. \textit{Риск:} Переобучение.
                \item \textit{SMOTE (и варианты)}: Генерация синтетических миноритарных объектов. Часто предпочтительнее Random Oversampling.
            \end{itemize}
    \end{itemize}
\end{myblock}

\begin{alerttextbox}{Важнейшее правило ресемплинга}
    Методы ресемплинга (Under/Over-sampling, SMOTE) должны применяться \textbf{только к обучающей части данных внутри каждого фолда CV}. \textbf{Никогда} не применяйте их ко всей выборке до CV или к validation/test set! Это ведет к \textbf{утечке данных} и завышенным оценкам.
\end{alerttextbox}

\begin{myblock}{{Подход 3: Взвешивание Классов/Примеров (Weighting)}}
    Назначение большего веса объектам миноритарного класса в функции потерь модели.
    \begin{itemize}[nosep, leftmargin=*]
        \item Заставляет модель уделять больше внимания ошибкам на миноритарном классе.
        \item Поддерживается многими алгоритмами (LogReg, SVM, Trees, Boostings).
        \item Параметры: \texttt{class\_weight='balanced'} (авто-подбор), \texttt{scale\_pos\_weight} (ручной множитель для позитивного класса в бустингах).
        \item Часто проще и эффективнее ресемплинга.
    \end{itemize}
\end{myblock}

\begin{myblock}{{Подход 4: Использование Алгоритмов, Устойчивых к Дисбалансу}}
    \begin{itemize}[nosep, leftmargin=*]
        \item Некоторые модели лучше справляются по умолчанию (e.g., ансамбли деревьев).
        \item Существуют специализированные ансамблевые методы (EasyEnsemble, BalanceCascade).
    \end{itemize}
\end{myblock}

\begin{myblock}{Подход 5: Изменение Порога Классификации}
    \begin{itemize}[nosep, leftmargin=*]
        \item Если модель выдает вероятности, можно подобрать оптимальный порог (не обязательно 0.5) для бинаризации.
        \item Порог выбирается на валидационной выборке для достижения нужного баланса Precision/Recall (e.g., максимизация F1).
    \end{itemize}
\end{myblock}

\begin{myblock}{Подход 6: Использовать Stratified K-Fold}
    Как уже упоминалось, Stratified K-Fold гарантирует репрезентативность классов в фолдах CV, что критически важно при дисбалансе.
\end{myblock}